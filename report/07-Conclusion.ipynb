{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering:\n",
    "\n",
    "We investigated collaborative filtering through memory-based and model-based methods, implementing simple user-based and item-based methods which were slow, and model-based methods - SVD and ALS - which were much more efficient, and allowed quick recommendations to be given. All of these methods gave recommendations which ranged in quality and performance depending on the availability of data. Next, we used PySpark to implement ALS and this increased the computational efficiency significantly, allowing us to quickly give recommendations for all of the users. This feature would allow us to scale our recommendation methods to large datasets and would be vital in developing our music recommendation system, which could theoretically have millions of users. We evaluated the performance of the PySpark ALS method use RMSE and found this to be very high, leading us to conclude that there is significant room for improvement in our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational autoencoders:\n",
    "\n",
    "We have explored the use of Variational Autoencoders as a means of creating a recommender system for music artists. To do this, we have refined our model by adjusting its hyperparameters and analysing its computational performance. Overall, we have seen that the model's hit rate and NDCG score are relatively low, but can be affected by optimising the use of batches, the activation function, and the number of layers in the VAE. The MSE was lower than that of the purely random generator, suggesting that our model was able to successfully capture some relationships in the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Neural Network:\n",
    "\n",
    "In section 5 we explored the use of Graph Neural Networks, particularly the LightGCN model, which was able to perform at a relatively high level, with recall around 0.27, and further predictions that were all similar, suggesting that the model successfully made links between similar artists. We also explored the use of GPU's in the model and how they would speed up the running of the model. Finally we looked at the resource usage of the model, mainly time requirements and GPU memory requirements."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
