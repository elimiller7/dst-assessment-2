{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from GNNfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = '..'\n",
    "artists = pd.read_csv(os.path.join(cwd,'data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join(cwd,'data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join(cwd,'data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join(cwd,'data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join(cwd,'data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join(cwd,'data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_artists['userID'].unique()\n",
    "singleartistusers = [user for user in users if len(get_artists(user,user_artists)) == 1]\n",
    "singleartistusersdf = user_artists[user_artists['userID'].isin(singleartistusers)]\n",
    "user_artists_temp = user_artists[~user_artists['userID'].isin(singleartistusers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_artists_train, user_artists_test = train_test_split(user_artists_temp, test_size = 0.2, stratify = user_artists_temp['userID'], random_state = 47)\n",
    "\n",
    "user_artists_train = pd.concat([user_artists_train,singleartistusersdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taggedartists_test = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'inner')\n",
    "user_taggedartists_train = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'left', indicator = True)\n",
    "user_taggedartists_train = user_taggedartists_train[user_taggedartists_train['_merge'] == 'left_only'].drop(columns = ['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [user_artists_train,user_artists_test,user_friends]\n",
    "\n",
    "filepath = os.path.join(cwd,'data','GNN')\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "\n",
    "for df in dfs:\n",
    "    df.to_csv(os.path.join(filepath,get_df_name(df, globals()) + '.txt'),sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dataset\n",
    "\n",
    "already has lastfm dataset defined but it is slightly different to ours, so we will add ours to dataloader.py. This consists of adding it as a class to dataloader.py, done by duplicating and editing the already existing LastFM class. We then add an elif statement to register.py to register it, and finally add it to the `all_dataset` list in world.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users)\n",
    "artistlist = list(artists['id'].unique())\n",
    "print(artistlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_write = '''\n",
    "class LastFM2(BasicDataset):\n",
    "    \"\"\"\n",
    "    Dataset type for pytorch\n",
    "    LastFM dataset 2\n",
    "    \"\"\"\n",
    "    def __init__(self, path=\"../data/GNN\"):\n",
    "        # train or test\n",
    "        cprint(\"loading [last fm]\")\n",
    "        self.mode_dict = {'train':0, \"test\":1}\n",
    "        self.mode    = self.mode_dict['train']\n",
    "        # self.n_users = 2100\n",
    "        # self.m_items = 18745\n",
    "        trainData = pd.read_table(join(path, 'user_artists_train.txt'), header=None)\n",
    "        print(trainData.head())\n",
    "        testData  = pd.read_table(join(path, 'user_artists_test.txt'), header=None)\n",
    "        print(testData.head())\n",
    "        trustNet  = pd.read_table(join(path, 'user_friends.txt'), header=None).to_numpy()\n",
    "        print(trustNet[:5])\n",
    "        trustNet -= 1\n",
    "        trainData-= 1\n",
    "        testData -= 1\n",
    "        self.trustNet  = trustNet\n",
    "        self.trainData = trainData\n",
    "        self.testData  = testData\n",
    "        self.trainUser = np.array(trainData[:][0])\n",
    "        self.trainUniqueUsers = np.unique(self.trainUser)\n",
    "        self.trainItem = np.array(trainData[:][1])\n",
    "        # self.trainDataSize = len(self.trainUser)\n",
    "        self.testUser  = np.array(testData[:][0])\n",
    "        self.testUniqueUsers = np.unique(self.testUser)\n",
    "        self.testItem  = np.array(testData[:][1])\n",
    "        self.Graph = None\n",
    "        print(f\"LastFm2 Sparsity : {(len(self.trainUser) + len(self.testUser))/self.n_users/self.m_items}\")\n",
    "        \n",
    "        # (users,users)\n",
    "        self.socialNet    = csr_matrix((np.ones(len(trustNet)), (trustNet[:,0], trustNet[:,1]) ), shape=(self.n_users,self.n_users))\n",
    "        # (users,items), bipartite graph\n",
    "        self.UserItemNet  = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem) ), shape=(self.n_users,self.m_items)) \n",
    "        \n",
    "        # pre-calculate\n",
    "        self._allPos = self.getUserPosItems(list(range(self.n_users)))\n",
    "        self.allNeg = []\n",
    "        allItems    = set(range(self.m_items))\n",
    "        for i in range(self.n_users):\n",
    "            pos = set(self._allPos[i])\n",
    "            neg = allItems - pos\n",
    "            self.allNeg.append(np.array(list(neg)))\n",
    "        self.__testDict = self.__build_test()\n",
    "\n",
    "    @property\n",
    "    def n_users(self):\n",
    "        return 2100\n",
    "    \n",
    "    @property\n",
    "    def m_items(self):\n",
    "        return 18745\n",
    "    \n",
    "    @property\n",
    "    def trainDataSize(self):\n",
    "        return len(self.trainUser)\n",
    "    \n",
    "    @property\n",
    "    def testDict(self):\n",
    "        return self.__testDict\n",
    "\n",
    "    @property\n",
    "    def allPos(self):\n",
    "        return self._allPos\n",
    "\n",
    "    def getSparseGraph(self):\n",
    "        if self.Graph is None:\n",
    "            user_dim = torch.LongTensor(self.trainUser)\n",
    "            item_dim = torch.LongTensor(self.trainItem)\n",
    "            \n",
    "            first_sub = torch.stack([user_dim, item_dim + self.n_users])\n",
    "            second_sub = torch.stack([item_dim+self.n_users, user_dim])\n",
    "            index = torch.cat([first_sub, second_sub], dim=1)\n",
    "            data = torch.ones(index.size(-1)).int()\n",
    "            self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            dense = self.Graph.to_dense()\n",
    "            D = torch.sum(dense, dim=1).float()\n",
    "            D[D==0.] = 1.\n",
    "            D_sqrt = torch.sqrt(D).unsqueeze(dim=0)\n",
    "            dense = dense/D_sqrt\n",
    "            dense = dense/D_sqrt.t()\n",
    "            index = dense.nonzero()\n",
    "            data  = dense[dense >= 1e-9]\n",
    "            assert len(index) == len(data)\n",
    "            self.Graph = torch.sparse.FloatTensor(index.t(), data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            self.Graph = self.Graph.coalesce().to(world.device)\n",
    "        return self.Graph\n",
    "\n",
    "    def __build_test(self):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            dict: {user: [items]}\n",
    "        \"\"\"\n",
    "        test_data = {}\n",
    "        for i, item in enumerate(self.testItem):\n",
    "            user = self.testUser[i]\n",
    "            if test_data.get(user):\n",
    "                test_data[user].append(item)\n",
    "            else:\n",
    "                test_data[user] = [item]\n",
    "        return test_data\n",
    "    \n",
    "    def getUserItemFeedback(self, users, items):\n",
    "        \"\"\"\n",
    "        users:\n",
    "            shape [-1]\n",
    "        items:\n",
    "            shape [-1]\n",
    "        return:\n",
    "            feedback [-1]\n",
    "        \"\"\"\n",
    "        # print(self.UserItemNet[users, items])\n",
    "        return np.array(self.UserItemNet[users, items]).astype('uint8').reshape((-1, ))\n",
    "    \n",
    "    def getUserPosItems(self, users):\n",
    "        posItems = []\n",
    "        for user in users:\n",
    "            posItems.append(self.UserItemNet[user].nonzero()[1])\n",
    "        return posItems\n",
    "    \n",
    "    def getUserNegItems(self, users):\n",
    "        negItems = []\n",
    "        for user in users:\n",
    "            negItems.append(self.allNeg[user])\n",
    "        return negItems\n",
    "            \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.trainUniqueUsers[index]\n",
    "        # return user_id and the positive items of the user\n",
    "        return user\n",
    "    \n",
    "    def switch2test(self):\n",
    "        \"\"\"\n",
    "        change dataset mode to offer test data to dataloader\n",
    "        \"\"\"\n",
    "        self.mode = self.mode_dict['test']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainUniqueUsers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaderpath = os.path.join('..','scripts','LightGCN','dataloader.py')\n",
    "dataloader = open(dataloaderpath)\n",
    "\n",
    "if 'class LastFM2(BasicDataset)' not in dataloader.read():\n",
    "    with open(dataloaderpath,'a') as file:\n",
    "        file.write(code_to_write)\n",
    "        print('Class added.')\n",
    "else:\n",
    "    print('Class already present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultspath = os.path.join('..','scripts','LightGCN','results')\n",
    "if not os.path.exists(resultspath):\n",
    "    os.makedirs(resultspath)\n",
    "resultsfile = os.path.join(resultspath,'results.csv')\n",
    "if os.path.exists(resultsfile):\n",
    "    os.remove(resultsfile)\n",
    "pd.DataFrame(columns=['precision','recall','ndcg']).to_csv(resultsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is cpu, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      ">>SEED: 47\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.00235706955576828\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "Device used is cpu, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.00235706955576828\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\LightGCN\\dataloader.py:487: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00026567]), 'recall': array([0.00053135]), 'ndcg': array([0.00040668])}\n",
      "EPOCH[1/10] loss0.686-|Sample:0.79|\n",
      "EPOCH[2/10] loss0.660-|Sample:0.68|\n",
      "EPOCH[3/10] loss0.571-|Sample:0.79|\n",
      "EPOCH[4/10] loss0.446-|Sample:0.68|\n",
      "EPOCH[5/10] loss0.350-|Sample:0.78|\n",
      "EPOCH[6/10] loss0.296-|Sample:0.67|\n",
      "EPOCH[7/10] loss0.265-|Sample:0.78|\n",
      "EPOCH[8/10] loss0.241-|Sample:0.78|\n",
      "EPOCH[9/10] loss0.224-|Sample:0.68|\n",
      "EPOCH[10/10] loss0.211-|Sample:0.79|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.0642933]), 'recall': array([0.13117884]), 'ndcg': array([0.13391279])}\n",
      "EPOCH[11/10] loss0.199-|Sample:0.66|\n",
      "Total time taken: 79.41200017929077\n"
     ]
    }
   ],
   "source": [
    "%run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=10 --device=CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is cuda, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      ">>SEED: 47\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 4\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "Device used is cuda, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 4\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\LightGCN\\dataloader.py:487: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00061105]), 'recall': array([0.00122801]), 'ndcg': array([0.00092211])}\n",
      "EPOCH[1/10] loss0.686-|Sample:0.67|\n",
      "EPOCH[2/10] loss0.661-|Sample:0.78|\n",
      "EPOCH[3/10] loss0.575-|Sample:0.77|\n",
      "EPOCH[4/10] loss0.451-|Sample:0.66|\n",
      "EPOCH[5/10] loss0.354-|Sample:0.77|\n",
      "EPOCH[6/10] loss0.298-|Sample:0.77|\n",
      "EPOCH[7/10] loss0.267-|Sample:0.65|\n",
      "EPOCH[8/10] loss0.243-|Sample:0.78|\n",
      "EPOCH[9/10] loss0.225-|Sample:0.66|\n",
      "EPOCH[10/10] loss0.211-|Sample:0.76|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.06259299]), 'recall': array([0.12805568]), 'ndcg': array([0.12743833])}\n",
      "EPOCH[11/10] loss0.200-|Sample:0.77|\n",
      "Total time taken: 16.980195999145508\n"
     ]
    }
   ],
   "source": [
    "%run -i \"../scripts/LightGCN/main.py\" --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=10 --device=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>SEED: 47\n",
      "Device used is cuda.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [10]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00063762]), 'recall': array([0.00063762]), 'ndcg': array([0.00060016])}\n",
      "EPOCH[1/100] loss0.686-|Sample:0.66|\n",
      "EPOCH[2/100] loss0.661-|Sample:0.66|\n",
      "EPOCH[3/100] loss0.575-|Sample:0.83|\n",
      "EPOCH[4/100] loss0.451-|Sample:0.69|\n",
      "EPOCH[5/100] loss0.354-|Sample:0.82|\n",
      "EPOCH[6/100] loss0.298-|Sample:0.67|\n",
      "EPOCH[7/100] loss0.267-|Sample:0.83|\n",
      "EPOCH[8/100] loss0.243-|Sample:0.66|\n",
      "EPOCH[9/100] loss0.225-|Sample:0.83|\n",
      "EPOCH[10/100] loss0.211-|Sample:0.68|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.08204038]), 'recall': array([0.08403358]), 'ndcg': array([0.10341764])}\n",
      "EPOCH[11/100] loss0.200-|Sample:0.83|\n",
      "EPOCH[12/100] loss0.190-|Sample:0.69|\n",
      "EPOCH[13/100] loss0.182-|Sample:0.83|\n",
      "EPOCH[14/100] loss0.168-|Sample:0.68|\n",
      "EPOCH[15/100] loss0.163-|Sample:0.68|\n",
      "EPOCH[16/100] loss0.157-|Sample:0.82|\n",
      "EPOCH[17/100] loss0.151-|Sample:0.67|\n",
      "EPOCH[18/100] loss0.148-|Sample:0.83|\n",
      "EPOCH[19/100] loss0.141-|Sample:0.71|\n",
      "EPOCH[20/100] loss0.135-|Sample:0.86|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10616366]), 'recall': array([0.10825068]), 'ndcg': array([0.13094217])}\n",
      "EPOCH[21/100] loss0.131-|Sample:0.66|\n",
      "EPOCH[22/100] loss0.126-|Sample:0.85|\n",
      "EPOCH[23/100] loss0.124-|Sample:0.66|\n",
      "EPOCH[24/100] loss0.119-|Sample:0.81|\n",
      "EPOCH[25/100] loss0.113-|Sample:0.66|\n",
      "EPOCH[26/100] loss0.112-|Sample:0.65|\n",
      "EPOCH[27/100] loss0.111-|Sample:0.80|\n",
      "EPOCH[28/100] loss0.104-|Sample:0.66|\n",
      "EPOCH[29/100] loss0.102-|Sample:0.98|\n",
      "EPOCH[30/100] loss0.100-|Sample:0.67|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.12013815]), 'recall': array([0.12296147]), 'ndcg': array([0.14766021])}\n",
      "EPOCH[31/100] loss0.099-|Sample:0.82|\n",
      "EPOCH[32/100] loss0.096-|Sample:0.66|\n",
      "EPOCH[33/100] loss0.094-|Sample:0.81|\n",
      "EPOCH[34/100] loss0.091-|Sample:0.66|\n",
      "EPOCH[35/100] loss0.088-|Sample:0.81|\n",
      "EPOCH[36/100] loss0.085-|Sample:0.66|\n",
      "EPOCH[37/100] loss0.087-|Sample:0.82|\n",
      "EPOCH[38/100] loss0.084-|Sample:0.68|\n",
      "EPOCH[39/100] loss0.084-|Sample:0.85|\n",
      "EPOCH[40/100] loss0.080-|Sample:0.65|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.12784272]), 'recall': array([0.13076852]), 'ndcg': array([0.15716793])}\n",
      "EPOCH[41/100] loss0.079-|Sample:0.66|\n",
      "EPOCH[42/100] loss0.078-|Sample:0.82|\n",
      "EPOCH[43/100] loss0.076-|Sample:0.67|\n",
      "EPOCH[44/100] loss0.071-|Sample:0.82|\n",
      "EPOCH[45/100] loss0.073-|Sample:0.68|\n",
      "EPOCH[46/100] loss0.071-|Sample:0.81|\n",
      "EPOCH[47/100] loss0.069-|Sample:0.66|\n",
      "EPOCH[48/100] loss0.069-|Sample:0.81|\n",
      "EPOCH[49/100] loss0.068-|Sample:0.66|\n",
      "EPOCH[50/100] loss0.068-|Sample:0.81|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.1335813]), 'recall': array([0.13650709]), 'ndcg': array([0.16390317])}\n",
      "EPOCH[51/100] loss0.067-|Sample:0.65|\n",
      "EPOCH[52/100] loss0.063-|Sample:0.65|\n",
      "EPOCH[53/100] loss0.063-|Sample:0.79|\n",
      "EPOCH[54/100] loss0.063-|Sample:0.65|\n",
      "EPOCH[55/100] loss0.062-|Sample:0.85|\n",
      "EPOCH[56/100] loss0.062-|Sample:0.68|\n",
      "EPOCH[57/100] loss0.061-|Sample:0.85|\n",
      "EPOCH[58/100] loss0.059-|Sample:0.67|\n",
      "EPOCH[59/100] loss0.057-|Sample:0.84|\n",
      "EPOCH[60/100] loss0.057-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.13878852]), 'recall': array([0.14188975]), 'ndcg': array([0.16983618])}\n",
      "EPOCH[61/100] loss0.057-|Sample:0.82|\n",
      "EPOCH[62/100] loss0.057-|Sample:0.66|\n",
      "EPOCH[63/100] loss0.056-|Sample:0.66|\n",
      "EPOCH[64/100] loss0.055-|Sample:0.80|\n",
      "EPOCH[65/100] loss0.054-|Sample:0.67|\n",
      "EPOCH[66/100] loss0.054-|Sample:0.82|\n",
      "EPOCH[67/100] loss0.052-|Sample:0.67|\n",
      "EPOCH[68/100] loss0.050-|Sample:0.82|\n",
      "EPOCH[69/100] loss0.052-|Sample:0.66|\n",
      "EPOCH[70/100] loss0.051-|Sample:0.83|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.14256111]), 'recall': array([0.14544979]), 'ndcg': array([0.1744298])}\n",
      "EPOCH[71/100] loss0.050-|Sample:0.66|\n",
      "EPOCH[72/100] loss0.049-|Sample:0.81|\n",
      "EPOCH[73/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[74/100] loss0.046-|Sample:0.82|\n",
      "EPOCH[75/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[76/100] loss0.047-|Sample:0.69|\n",
      "EPOCH[77/100] loss0.047-|Sample:0.85|\n",
      "EPOCH[78/100] loss0.046-|Sample:0.68|\n",
      "EPOCH[79/100] loss0.044-|Sample:0.88|\n",
      "EPOCH[80/100] loss0.045-|Sample:0.68|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.14702444]), 'recall': array([0.15014844]), 'ndcg': array([0.17898869])}\n",
      "EPOCH[81/100] loss0.043-|Sample:0.89|\n",
      "EPOCH[82/100] loss0.043-|Sample:0.70|\n",
      "EPOCH[83/100] loss0.044-|Sample:0.81|\n",
      "EPOCH[84/100] loss0.044-|Sample:0.66|\n",
      "EPOCH[85/100] loss0.043-|Sample:0.84|\n",
      "EPOCH[86/100] loss0.041-|Sample:0.66|\n",
      "EPOCH[87/100] loss0.041-|Sample:0.81|\n",
      "EPOCH[88/100] loss0.041-|Sample:0.66|\n",
      "EPOCH[89/100] loss0.040-|Sample:0.66|\n",
      "EPOCH[90/100] loss0.039-|Sample:0.80|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.15031881]), 'recall': array([0.1534369]), 'ndcg': array([0.18277646])}\n",
      "EPOCH[91/100] loss0.042-|Sample:0.66|\n",
      "EPOCH[92/100] loss0.040-|Sample:0.81|\n",
      "EPOCH[93/100] loss0.040-|Sample:0.66|\n",
      "EPOCH[94/100] loss0.039-|Sample:0.81|\n",
      "EPOCH[95/100] loss0.038-|Sample:0.66|\n",
      "EPOCH[96/100] loss0.039-|Sample:0.82|\n",
      "EPOCH[97/100] loss0.039-|Sample:0.67|\n",
      "EPOCH[98/100] loss0.037-|Sample:0.67|\n",
      "EPOCH[99/100] loss0.037-|Sample:0.82|\n",
      "EPOCH[100/100] loss0.037-|Sample:0.69|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.15276302]), 'recall': array([0.15587373]), 'ndcg': array([0.18600051])}\n",
      "EPOCH[101/100] loss0.036-|Sample:0.82|\n",
      "Total time taken: 106.88786482810974\n",
      ">>SEED: 47\n",
      "Device used is cuda.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00061105]), 'recall': array([0.00122801]), 'ndcg': array([0.00092211])}\n",
      "EPOCH[1/100] loss0.686-|Sample:0.66|\n",
      "EPOCH[2/100] loss0.661-|Sample:0.81|\n",
      "EPOCH[3/100] loss0.575-|Sample:0.66|\n",
      "EPOCH[4/100] loss0.451-|Sample:0.82|\n",
      "EPOCH[5/100] loss0.354-|Sample:0.67|\n",
      "EPOCH[6/100] loss0.298-|Sample:0.86|\n",
      "EPOCH[7/100] loss0.267-|Sample:0.68|\n",
      "EPOCH[8/100] loss0.243-|Sample:0.84|\n",
      "EPOCH[9/100] loss0.225-|Sample:0.66|\n",
      "EPOCH[10/100] loss0.211-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.06259299]), 'recall': array([0.12805568]), 'ndcg': array([0.12743833])}\n",
      "EPOCH[11/100] loss0.200-|Sample:0.84|\n",
      "EPOCH[12/100] loss0.190-|Sample:0.66|\n",
      "EPOCH[13/100] loss0.182-|Sample:0.81|\n",
      "EPOCH[14/100] loss0.168-|Sample:0.66|\n",
      "EPOCH[15/100] loss0.163-|Sample:0.82|\n",
      "EPOCH[16/100] loss0.157-|Sample:0.67|\n",
      "EPOCH[17/100] loss0.151-|Sample:0.85|\n",
      "EPOCH[18/100] loss0.148-|Sample:0.67|\n",
      "EPOCH[19/100] loss0.141-|Sample:0.84|\n",
      "EPOCH[20/100] loss0.135-|Sample:0.67|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.07555792]), 'recall': array([0.1541654]), 'ndcg': array([0.15604911])}\n",
      "EPOCH[21/100] loss0.131-|Sample:0.66|\n",
      "EPOCH[22/100] loss0.126-|Sample:0.80|\n",
      "EPOCH[23/100] loss0.124-|Sample:0.66|\n",
      "EPOCH[24/100] loss0.119-|Sample:0.80|\n",
      "EPOCH[25/100] loss0.113-|Sample:0.66|\n",
      "EPOCH[26/100] loss0.112-|Sample:0.86|\n",
      "EPOCH[27/100] loss0.111-|Sample:0.66|\n",
      "EPOCH[28/100] loss0.104-|Sample:0.81|\n",
      "EPOCH[29/100] loss0.102-|Sample:0.70|\n",
      "EPOCH[30/100] loss0.100-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.08475027]), 'recall': array([0.17276707]), 'ndcg': array([0.17519006])}\n",
      "EPOCH[31/100] loss0.099-|Sample:0.65|\n",
      "EPOCH[32/100] loss0.096-|Sample:0.67|\n",
      "EPOCH[33/100] loss0.094-|Sample:0.81|\n",
      "EPOCH[34/100] loss0.091-|Sample:0.66|\n",
      "EPOCH[35/100] loss0.088-|Sample:0.80|\n",
      "EPOCH[36/100] loss0.085-|Sample:0.65|\n",
      "EPOCH[37/100] loss0.087-|Sample:0.81|\n",
      "EPOCH[38/100] loss0.084-|Sample:0.67|\n",
      "EPOCH[39/100] loss0.084-|Sample:0.80|\n",
      "EPOCH[40/100] loss0.080-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.09149841]), 'recall': array([0.18634431]), 'ndcg': array([0.18788289])}\n",
      "EPOCH[41/100] loss0.079-|Sample:0.82|\n",
      "EPOCH[42/100] loss0.078-|Sample:0.65|\n",
      "EPOCH[43/100] loss0.076-|Sample:0.65|\n",
      "EPOCH[44/100] loss0.071-|Sample:0.81|\n",
      "EPOCH[45/100] loss0.073-|Sample:0.66|\n",
      "EPOCH[46/100] loss0.071-|Sample:0.81|\n",
      "EPOCH[47/100] loss0.069-|Sample:0.70|\n",
      "EPOCH[48/100] loss0.069-|Sample:0.81|\n",
      "EPOCH[49/100] loss0.068-|Sample:0.66|\n",
      "EPOCH[50/100] loss0.068-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.09636026]), 'recall': array([0.19607223]), 'ndcg': array([0.19684011])}\n",
      "EPOCH[51/100] loss0.067-|Sample:0.66|\n",
      "EPOCH[52/100] loss0.063-|Sample:0.81|\n",
      "EPOCH[53/100] loss0.063-|Sample:0.66|\n",
      "EPOCH[54/100] loss0.063-|Sample:0.80|\n",
      "EPOCH[55/100] loss0.062-|Sample:0.66|\n",
      "EPOCH[56/100] loss0.062-|Sample:0.66|\n",
      "EPOCH[57/100] loss0.061-|Sample:0.80|\n",
      "EPOCH[58/100] loss0.059-|Sample:0.66|\n",
      "EPOCH[59/100] loss0.057-|Sample:0.80|\n",
      "EPOCH[60/100] loss0.057-|Sample:0.67|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.1]), 'recall': array([0.20335172]), 'ndcg': array([0.20383488])}\n",
      "EPOCH[61/100] loss0.057-|Sample:0.81|\n",
      "EPOCH[62/100] loss0.057-|Sample:0.66|\n",
      "EPOCH[63/100] loss0.056-|Sample:0.81|\n",
      "EPOCH[64/100] loss0.055-|Sample:0.66|\n",
      "EPOCH[65/100] loss0.054-|Sample:0.84|\n",
      "EPOCH[66/100] loss0.054-|Sample:0.66|\n",
      "EPOCH[67/100] loss0.052-|Sample:0.81|\n",
      "EPOCH[68/100] loss0.050-|Sample:0.66|\n",
      "EPOCH[69/100] loss0.052-|Sample:0.80|\n",
      "EPOCH[70/100] loss0.051-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10255048]), 'recall': array([0.2084299]), 'ndcg': array([0.20937135])}\n",
      "EPOCH[71/100] loss0.050-|Sample:0.66|\n",
      "EPOCH[72/100] loss0.049-|Sample:0.81|\n",
      "EPOCH[73/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[74/100] loss0.046-|Sample:0.83|\n",
      "EPOCH[75/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[76/100] loss0.047-|Sample:0.82|\n",
      "EPOCH[77/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[78/100] loss0.046-|Sample:0.81|\n",
      "EPOCH[79/100] loss0.044-|Sample:0.65|\n",
      "EPOCH[80/100] loss0.045-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10563231]), 'recall': array([0.21465176]), 'ndcg': array([0.21485627])}\n",
      "EPOCH[81/100] loss0.043-|Sample:0.65|\n",
      "EPOCH[82/100] loss0.043-|Sample:0.65|\n",
      "EPOCH[83/100] loss0.044-|Sample:0.81|\n",
      "EPOCH[84/100] loss0.044-|Sample:0.66|\n",
      "EPOCH[85/100] loss0.043-|Sample:0.83|\n",
      "EPOCH[86/100] loss0.041-|Sample:0.67|\n",
      "EPOCH[87/100] loss0.041-|Sample:0.81|\n",
      "EPOCH[88/100] loss0.041-|Sample:0.66|\n",
      "EPOCH[89/100] loss0.040-|Sample:0.65|\n",
      "EPOCH[90/100] loss0.039-|Sample:0.81|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10783741]), 'recall': array([0.21906196]), 'ndcg': array([0.21926031])}\n",
      "EPOCH[91/100] loss0.042-|Sample:0.66|\n",
      "EPOCH[92/100] loss0.040-|Sample:0.81|\n",
      "EPOCH[93/100] loss0.040-|Sample:0.68|\n",
      "EPOCH[94/100] loss0.039-|Sample:0.84|\n",
      "EPOCH[95/100] loss0.038-|Sample:0.69|\n",
      "EPOCH[96/100] loss0.039-|Sample:0.82|\n",
      "EPOCH[97/100] loss0.039-|Sample:0.66|\n",
      "EPOCH[98/100] loss0.037-|Sample:0.81|\n",
      "EPOCH[99/100] loss0.037-|Sample:0.66|\n",
      "EPOCH[100/100] loss0.037-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10969713]), 'recall': array([0.2232242]), 'ndcg': array([0.22323362])}\n",
      "EPOCH[101/100] loss0.036-|Sample:0.66|\n",
      "Total time taken: 105.55590343475342\n",
      ">>SEED: 47\n",
      "Device used is cuda.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00061105]), 'recall': array([0.00122801]), 'ndcg': array([0.00092211])}\n",
      "EPOCH[1/100] loss0.686-|Sample:0.67|\n",
      "EPOCH[2/100] loss0.661-|Sample:0.81|\n",
      "EPOCH[3/100] loss0.575-|Sample:0.67|\n",
      "EPOCH[4/100] loss0.451-|Sample:0.81|\n",
      "EPOCH[5/100] loss0.354-|Sample:0.66|\n",
      "EPOCH[6/100] loss0.298-|Sample:0.83|\n",
      "EPOCH[7/100] loss0.267-|Sample:0.66|\n",
      "EPOCH[8/100] loss0.243-|Sample:0.81|\n",
      "EPOCH[9/100] loss0.225-|Sample:0.66|\n",
      "EPOCH[10/100] loss0.211-|Sample:0.81|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.06259299]), 'recall': array([0.12805568]), 'ndcg': array([0.12743833])}\n",
      "EPOCH[11/100] loss0.200-|Sample:0.66|\n",
      "EPOCH[12/100] loss0.190-|Sample:0.65|\n",
      "EPOCH[13/100] loss0.182-|Sample:0.84|\n",
      "EPOCH[14/100] loss0.168-|Sample:0.66|\n",
      "EPOCH[15/100] loss0.163-|Sample:0.82|\n",
      "EPOCH[16/100] loss0.157-|Sample:0.66|\n",
      "EPOCH[17/100] loss0.151-|Sample:0.80|\n",
      "EPOCH[18/100] loss0.148-|Sample:0.67|\n",
      "EPOCH[19/100] loss0.141-|Sample:0.82|\n",
      "EPOCH[20/100] loss0.135-|Sample:0.65|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.07555792]), 'recall': array([0.1541654]), 'ndcg': array([0.15604911])}\n",
      "EPOCH[21/100] loss0.131-|Sample:0.67|\n",
      "EPOCH[22/100] loss0.126-|Sample:0.81|\n",
      "EPOCH[23/100] loss0.124-|Sample:0.67|\n",
      "EPOCH[24/100] loss0.119-|Sample:0.82|\n",
      "EPOCH[25/100] loss0.113-|Sample:0.66|\n",
      "EPOCH[26/100] loss0.112-|Sample:0.81|\n",
      "EPOCH[27/100] loss0.111-|Sample:0.66|\n",
      "EPOCH[28/100] loss0.104-|Sample:0.81|\n",
      "EPOCH[29/100] loss0.102-|Sample:0.67|\n",
      "EPOCH[30/100] loss0.100-|Sample:0.83|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.08475027]), 'recall': array([0.17276707]), 'ndcg': array([0.17519006])}\n",
      "EPOCH[31/100] loss0.099-|Sample:0.66|\n",
      "EPOCH[32/100] loss0.096-|Sample:0.66|\n",
      "EPOCH[33/100] loss0.094-|Sample:0.80|\n",
      "EPOCH[34/100] loss0.091-|Sample:0.68|\n",
      "EPOCH[35/100] loss0.088-|Sample:0.81|\n",
      "EPOCH[36/100] loss0.085-|Sample:0.65|\n",
      "EPOCH[37/100] loss0.087-|Sample:0.82|\n",
      "EPOCH[38/100] loss0.084-|Sample:0.65|\n",
      "EPOCH[39/100] loss0.084-|Sample:0.82|\n",
      "EPOCH[40/100] loss0.080-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.09149841]), 'recall': array([0.18634431]), 'ndcg': array([0.18788289])}\n",
      "EPOCH[41/100] loss0.079-|Sample:0.81|\n",
      "EPOCH[42/100] loss0.078-|Sample:0.66|\n",
      "EPOCH[43/100] loss0.076-|Sample:0.82|\n",
      "EPOCH[44/100] loss0.071-|Sample:0.67|\n",
      "EPOCH[45/100] loss0.073-|Sample:0.68|\n",
      "EPOCH[46/100] loss0.071-|Sample:0.82|\n",
      "EPOCH[47/100] loss0.069-|Sample:0.66|\n",
      "EPOCH[48/100] loss0.069-|Sample:0.81|\n",
      "EPOCH[49/100] loss0.068-|Sample:0.67|\n",
      "EPOCH[50/100] loss0.068-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.09636026]), 'recall': array([0.19607223]), 'ndcg': array([0.19684011])}\n",
      "EPOCH[51/100] loss0.067-|Sample:0.66|\n",
      "EPOCH[52/100] loss0.063-|Sample:0.81|\n",
      "EPOCH[53/100] loss0.063-|Sample:0.66|\n",
      "EPOCH[54/100] loss0.063-|Sample:0.82|\n",
      "EPOCH[55/100] loss0.062-|Sample:0.66|\n",
      "EPOCH[56/100] loss0.062-|Sample:0.66|\n",
      "EPOCH[57/100] loss0.061-|Sample:0.82|\n",
      "EPOCH[58/100] loss0.059-|Sample:0.65|\n",
      "EPOCH[59/100] loss0.057-|Sample:0.82|\n",
      "EPOCH[60/100] loss0.057-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.1]), 'recall': array([0.20335172]), 'ndcg': array([0.20383488])}\n",
      "EPOCH[61/100] loss0.057-|Sample:0.81|\n",
      "EPOCH[62/100] loss0.057-|Sample:0.66|\n",
      "EPOCH[63/100] loss0.056-|Sample:0.81|\n",
      "EPOCH[64/100] loss0.055-|Sample:0.67|\n",
      "EPOCH[65/100] loss0.054-|Sample:0.65|\n",
      "EPOCH[66/100] loss0.054-|Sample:0.83|\n",
      "EPOCH[67/100] loss0.052-|Sample:0.67|\n",
      "EPOCH[68/100] loss0.050-|Sample:0.81|\n",
      "EPOCH[69/100] loss0.052-|Sample:0.69|\n",
      "EPOCH[70/100] loss0.051-|Sample:0.82|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10255048]), 'recall': array([0.2084299]), 'ndcg': array([0.20937135])}\n",
      "EPOCH[71/100] loss0.050-|Sample:0.66|\n",
      "EPOCH[72/100] loss0.049-|Sample:0.82|\n",
      "EPOCH[73/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[74/100] loss0.046-|Sample:0.67|\n",
      "EPOCH[75/100] loss0.047-|Sample:0.81|\n",
      "EPOCH[76/100] loss0.047-|Sample:0.66|\n",
      "EPOCH[77/100] loss0.047-|Sample:0.81|\n",
      "EPOCH[78/100] loss0.046-|Sample:0.68|\n",
      "EPOCH[79/100] loss0.044-|Sample:0.81|\n",
      "EPOCH[80/100] loss0.045-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10563231]), 'recall': array([0.21465176]), 'ndcg': array([0.21485627])}\n",
      "EPOCH[81/100] loss0.043-|Sample:0.81|\n",
      "EPOCH[82/100] loss0.043-|Sample:0.67|\n",
      "EPOCH[83/100] loss0.044-|Sample:0.81|\n",
      "EPOCH[84/100] loss0.044-|Sample:0.66|\n",
      "EPOCH[85/100] loss0.043-|Sample:0.81|\n",
      "EPOCH[86/100] loss0.041-|Sample:0.66|\n",
      "EPOCH[87/100] loss0.041-|Sample:0.81|\n",
      "EPOCH[88/100] loss0.041-|Sample:0.66|\n",
      "EPOCH[89/100] loss0.040-|Sample:0.66|\n",
      "EPOCH[90/100] loss0.039-|Sample:0.83|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10783741]), 'recall': array([0.21906196]), 'ndcg': array([0.21926031])}\n",
      "EPOCH[91/100] loss0.042-|Sample:0.66|\n",
      "EPOCH[92/100] loss0.040-|Sample:0.81|\n",
      "EPOCH[93/100] loss0.040-|Sample:0.66|\n",
      "EPOCH[94/100] loss0.039-|Sample:0.81|\n",
      "EPOCH[95/100] loss0.038-|Sample:0.66|\n",
      "EPOCH[96/100] loss0.039-|Sample:0.81|\n",
      "EPOCH[97/100] loss0.039-|Sample:0.66|\n",
      "EPOCH[98/100] loss0.037-|Sample:0.66|\n",
      "EPOCH[99/100] loss0.037-|Sample:0.81|\n",
      "EPOCH[100/100] loss0.037-|Sample:0.67|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.10969713]), 'recall': array([0.2232242]), 'ndcg': array([0.22323362])}\n",
      "EPOCH[101/100] loss0.036-|Sample:0.81|\n",
      "Total time taken: 104.86983799934387\n"
     ]
    }
   ],
   "source": [
    "%run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[10]\" --recdim=64 --epochs=100 --device=GPU\n",
    "%run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=100 --device=GPU\n",
    "%run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=100 --device=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LightGCN\n",
    "from register import dataset\n",
    "\n",
    "Recmodel = register.MODELS[world.model_name](world.config, dataset).to(world.device)\n",
    "checkpoint = torch.load('../scripts/code/checkpoints/lgn-lastfm2-3-64.pth.tar')\n",
    "Recmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 2\n",
    "user_tensor = torch.tensor([user_id]).to(world.device)\n",
    "user_artist_test_list = get_artists(user_id, user_artists_test)\n",
    "\n",
    "for artist_id in user_artist_test_list:\n",
    "    artist_tensor = torch.tensor([artist_id]).to(world.device)\n",
    "    recommendation_score = Recmodel(user_tensor,artist_tensor)\n",
    "    print(f'For user {user_id}, artist {artist_id} is recommended with score {recommendation_score.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(os.path.join('..','scripts','LightGCN','results','results.csv'),index_col='Unnamed: 0')\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "for column in results.columns:\n",
    "    plt.plot(results.index,results[column],'--',label=column,)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
