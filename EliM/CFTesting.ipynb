{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "artists = pd.read_csv(os.path.join('..','data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join('..','data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join('..','data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join('..','data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join('..','data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join('..','data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns from the Artists dataset\n",
    "artists_cleaned = artists.drop(columns=['url', 'pictureURL']).drop_duplicates(keep='first') \n",
    "\n",
    "# Drop the irrelevant columns in the Tags dataset\n",
    "tags_cleaned = tags.drop_duplicates(keep='first') \n",
    "\n",
    "# For the User-Artists dataset, we can filter out rows with a weight of 0, as they show no meaningful interaction\n",
    "# user_artists_cleaned = user_artists[user_artists['weight'] > 0]\n",
    "user_artists_cleaned = user_artists.drop_duplicates(keep='first') \n",
    "\n",
    "# Drop duplicates from the User-Tagged Artists Timestamps dataset\n",
    "user_taggedartists_timestamps_cleaned = user_taggedartists_timestamps.drop_duplicates(keep='first') \n",
    "\n",
    "# Convert timestamps from ms to datetime format\n",
    "user_taggedartists_timestamps_cleaned['timestamp'] = pd.to_datetime(user_taggedartists_timestamps_cleaned['timestamp'], unit='ms')\n",
    "\n",
    "# Drop duplicates from the User-Friends dataset\n",
    "user_friends_cleaned = user_friends.drop_duplicates(keep='first') \n",
    "\n",
    "# # Output cleaned datasets for inspection\n",
    "# print(\"Cleaned Artists dataset:\", artists_cleaned.info(), artists_cleaned.head())\n",
    "# print(\"Cleaned Tags dataset:\", tags_cleaned.info(), tags_cleaned.head())\n",
    "# print(\"Cleaned User-Artists dataset:\", user_artists_cleaned.info(), user_artists_cleaned.head())\n",
    "# print(\"Cleaned User-Tagged Artists Timestamps dataset:\", user_taggedartists_timestamps_cleaned.info(), user_taggedartists_timestamps_cleaned.head())\n",
    "# print(\"Cleaned User-Friends dataset:\", user_friends_cleaned.info(), user_friends_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map artistID to artistName\n",
    "artist_id_to_name = dict(zip(artists['id'], artists['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userID  artistID  weight\n",
      "0           2        51   13883\n",
      "1           2        52   11690\n",
      "2           2        53   11351\n",
      "3           2        54   10300\n",
      "4           2        55    8983\n",
      "...       ...       ...     ...\n",
      "92829    2100     18726     337\n",
      "92830    2100     18727     297\n",
      "92831    2100     18728     281\n",
      "92832    2100     18729     280\n",
      "92833    2100     18730     263\n",
      "\n",
      "[92834 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(user_artists_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train-Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions: 74267\n",
      "Test interactions: 18567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure user_artists_cleaned has non-zero weights\n",
    "user_artists_cleaned = user_artists_cleaned[user_artists_cleaned['weight'] > 0]\n",
    "\n",
    "# Perform global train-test split\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verification\n",
    "print(f\"Train interactions: {train_data.shape[0]}\")\n",
    "print(f\"Test interactions: {test_data.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Implementation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 74267\n",
      "Test data size: 18567\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_similarity_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Example: Get top 5 user-based recommendations for user with userID=2\u001b[39;00m\n\u001b[0;32m     64\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 65\u001b[0m user_based_recommendations \u001b[38;5;241m=\u001b[39m get_user_based_recommendations(user_id, \u001b[43muser_similarity_df\u001b[49m, user_artist_matrix, artist_id_to_name, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_matrix\u001b[38;5;241m=\u001b[39mtrain_matrix, test_matrix\u001b[38;5;241m=\u001b[39mtest_matrix)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Display user-based recommendations in the required format\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop User-Based Recommendations for User 2:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_similarity_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to get user-based recommendations\n",
    "def get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=10, train_matrix=None, test_matrix=None):\n",
    "    # Print the current train and test data used for this run\n",
    "    print(f\"Training data for user {user_id}:\")\n",
    "    print(train_matrix.loc[user_id])  # Training data for the specific user\n",
    "    print(f\"Test data for user {user_id}:\")\n",
    "    print(test_matrix.loc[user_id])  # Test data for the specific user\n",
    "    \n",
    "    # Get the most similar users (excluding the user itself)\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]\n",
    "\n",
    "    recommendations = {}\n",
    "    for similar_user in similar_users:\n",
    "        # Get the artists this similar user has interacted with (non-zero values)\n",
    "        interacted_artists = user_artist_matrix.loc[similar_user][user_artist_matrix.loc[similar_user] > 0].index.tolist()\n",
    "\n",
    "        for artist in interacted_artists:\n",
    "            # Only consider artists the target user has not interacted with\n",
    "            if artist not in user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist():\n",
    "                # Add the artist to recommendations with a score (using the scaled similarity as a weight)\n",
    "                if artist not in recommendations:\n",
    "                    recommendations[artist] = user_similarity_df[user_id][similar_user]\n",
    "                else:\n",
    "                    # Add the weight of similarity to the current score\n",
    "                    recommendations[artist] += user_similarity_df[user_id][similar_user]\n",
    "\n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Convert artist IDs to names and prepare the final list with IDs, names, and scores\n",
    "    recommended_artists = [(artist, artist_id_to_name.get(artist, \"Unknown\"), score) for artist, score in sorted_recommendations[:top_n]]\n",
    "\n",
    "    return recommended_artists\n",
    "\n",
    "# Global train-test split (ensure this is applied once at the start)\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verify the train-test splits\n",
    "print(f\"Train data size: {train_data.shape[0]}\")\n",
    "print(f\"Test data size: {test_data.shape[0]}\")\n",
    "\n",
    "# Example: Get top 5 user-based recommendations for user with userID=2\n",
    "user_id = 2\n",
    "user_based_recommendations = get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=5, train_matrix=train_matrix, test_matrix=test_matrix)\n",
    "\n",
    "# Display user-based recommendations in the required format\n",
    "print(\"Top User-Based Recommendations for User 2:\")\n",
    "for artist_id, artist_name, score in user_based_recommendations:\n",
    "    print(f\"Artist ID: {artist_id}, Artist: {artist_name}, Similarity Score: {score:.2f}\")\n",
    "\n",
    "# Function to evaluate recommendations on test data\n",
    "def evaluate_recommendations(user_id, user_similarity_df_train, train_matrix, test_matrix, artist_id_to_name, top_n=10):\n",
    "    recommended_artists = get_user_based_recommendations(user_id, user_similarity_df_train, train_matrix, artist_id_to_name, top_n, train_matrix, test_matrix)\n",
    "\n",
    "    # Get the actual interacted artists from the test set\n",
    "    actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    # Extract recommended artist IDs from the recommendations list\n",
    "    recommended_artists_ids = [artist_id for artist_id, _, _ in recommended_artists]\n",
    "\n",
    "    # Precision at K\n",
    "    precision_at_k = precision_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                                     [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # Recall at K\n",
    "    recall_at_k = recall_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                               [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # F1 at K\n",
    "    f1_at_k = f1_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                        [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    return precision_at_k, recall_at_k, f1_at_k\n",
    "\n",
    "# Example: Evaluate recommendations for a user in the test set\n",
    "precision_at_k, recall_at_k, f1_at_k = evaluate_recommendations(user_id=2, \n",
    "                                                                user_similarity_df_train=user_similarity_df_train, \n",
    "                                                                train_matrix=train_matrix, \n",
    "                                                                test_matrix=test_matrix, \n",
    "                                                                artist_id_to_name=artist_id_to_name, \n",
    "                                                                top_n=10)\n",
    "\n",
    "print(f\"Precision@K: {precision_at_k}\")\n",
    "print(f\"Recall@K: {recall_at_k}\")\n",
    "print(f\"F1@K: {f1_at_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.0        17584\n",
      "2382.0         1\n",
      "2119.0         1\n",
      "1990.0         1\n",
      "1972.0         1\n",
      "1948.0         1\n",
      "1868.0         1\n",
      "1792.0         1\n",
      "1740.0         1\n",
      "1638.0         1\n",
      "1594.0         1\n",
      "1559.0         1\n",
      "1553.0         1\n",
      "1519.0         1\n",
      "1438.0         1\n",
      "1411.0         1\n",
      "1407.0         1\n",
      "1373.0         1\n",
      "1363.0         1\n",
      "1342.0         1\n",
      "1337.0         1\n",
      "1332.0         1\n",
      "1330.0         1\n",
      "2120.0         1\n",
      "2397.0         1\n",
      "13883.0        1\n",
      "2547.0         1\n",
      "11690.0        1\n",
      "11351.0        1\n",
      "10300.0        1\n",
      "8983.0         1\n",
      "6152.0         1\n",
      "5955.0         1\n",
      "4616.0         1\n",
      "4147.0         1\n",
      "3923.0         1\n",
      "3782.0         1\n",
      "3735.0         1\n",
      "3644.0         1\n",
      "3579.0         1\n",
      "3312.0         1\n",
      "3301.0         1\n",
      "2927.0         1\n",
      "2720.0         1\n",
      "2686.0         1\n",
      "2654.0         1\n",
      "2619.0         1\n",
      "2584.0         1\n",
      "1315.0         1\n",
      "Name: count, dtype: int64\n",
      "2\n",
      "0.0       17630\n",
      "4337.0        1\n",
      "1471.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.loc[user_id].value_counts())\n",
    "print(test_matrix.loc[user_id].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test data is extremely sparse, with a large number of zeroes. This is significantly affecting the performance of our recommendations, hence, we need to use different methods to overcome this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based Implementation Testing - EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a user-artist interaction matrix\n",
    "user_artist_matrix = user_artists_cleaned.pivot(index='userID', columns='artistID', values='weight')\n",
    "user_artist_matrix = user_artist_matrix.fillna(0)\n",
    "\n",
    "# Compute cosine similarity between items (artists in this case)\n",
    "item_similarity = cosine_similarity(user_artist_matrix.T)  # Transpose to compute similarity between artists\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=user_artist_matrix.columns, columns=user_artist_matrix.columns)\n",
    "\n",
    "# Function to get item-based recommendations for a user\n",
    "def get_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, top_n=10):\n",
    "    if user_id not in user_artist_matrix.index:\n",
    "        raise ValueError(f\"user_id {user_id} not found in user_artist_matrix\")\n",
    "    \n",
    "    # Get the artists the user has interacted with (non-zero values)\n",
    "    interacted_artists = user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist()\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # For each artist the user has interacted with, find similar artists\n",
    "    for artist in interacted_artists:\n",
    "        similar_artists = item_similarity_df[artist].sort_values(ascending=False).index[1:]  # Exclude the artist itself\n",
    "        \n",
    "        for similar_artist in similar_artists:\n",
    "            if similar_artist not in user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist():\n",
    "                if similar_artist not in recommendations:\n",
    "                    recommendations[similar_artist] = item_similarity_df[artist][similar_artist]\n",
    "                else:\n",
    "                    recommendations[similar_artist] += item_similarity_df[artist][similar_artist]\n",
    "    \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert artist IDs to names using artist_id_to_name\n",
    "    recommended_artists = [(artist_id_to_name.get(artist_id, \"Unknown\"), score) for artist_id, score in sorted_recommendations[:top_n]]\n",
    "    return recommended_artists\n",
    "\n",
    "# Precision@K for a single user\n",
    "def precision_at_k_single_user(recommended_artists, actual_artists, k):\n",
    "    recommended_artists_k = [artist for artist, _ in recommended_artists[:k]]\n",
    "    relevant_items = set(recommended_artists_k).intersection(set(actual_artists))\n",
    "    \n",
    "    if k == 0: \n",
    "        return 0\n",
    "    \n",
    "    return len(relevant_items) / k\n",
    "\n",
    "# Function to create a train-test split for each user (80% train, 20% test)\n",
    "def get_train_test_data(user_artist_matrix, user_id, test_size=0.2):\n",
    "    user_data = user_artist_matrix.loc[user_id]\n",
    "    non_zero_interactions = user_data[user_data > 0]\n",
    "    \n",
    "    train_data, test_data = train_test_split(non_zero_interactions.index, test_size=test_size)\n",
    "    \n",
    "    train_data = user_artist_matrix.loc[user_id, train_data]\n",
    "    test_data = user_artist_matrix.loc[user_id, test_data]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Evaluate Precision@K for a single user using train-test split\n",
    "def evaluate_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, k=10):\n",
    "    # Get train and test data for the user\n",
    "    train_data, test_data = get_train_test_data(user_artist_matrix, user_id)\n",
    "    \n",
    "    if len(test_data) == 0:\n",
    "        print(f\"User {user_id} has no interactions in the test set.\")\n",
    "        return None\n",
    "    \n",
    "    # Convert test data artist IDs to names\n",
    "    test_data_artist_names = [artist_id_to_name.get(artist_id, \"Unknown\") for artist_id in test_data.tolist()]\n",
    "    \n",
    "    print(f\"Test data for User {user_id}: {test_data_artist_names}\")\n",
    "    \n",
    "    # Get item-based recommendations for the user\n",
    "    recommendations = get_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, top_n=k)\n",
    "    \n",
    "    print(f\"Recommended artists for User {user_id}: {recommendations}\")\n",
    "    \n",
    "    recommended_artists = [artist for artist, _ in recommendations]\n",
    "    \n",
    "    # Precision@K evaluation\n",
    "    precision = precision_at_k_single_user(recommendations, test_data_artist_names, k)\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data for User 400: ['Enigma', 'Pleq & Chihiro', 'Café Del Mar', 'Prefab Sprout', 'Napalm Death', 'Icehouse', 'Cock Robin', 'ABC', 'Talk Talk', 'Alicia Keys']\n",
      "Recommended artists for User 400: [('The Pussycat Dolls', 6.075895826180479), ('Lily Allen', 5.7880441242910905), ('Natasha Bedingfield', 5.588535556689219), ('Jordin Sparks', 5.248566112199366), ('Gwen Stefani', 5.240362225570055), ('Cascada', 4.9372139515057025), ('Cheryl Cole', 4.824498405678474), ('Karl Wolf', 4.709049898458179), ('Outlandish', 4.709049898458179), ('Cameron Cartio', 4.709049898458179)]\n",
      "\n",
      "Precision@10 for User 400: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluate Precision@K for a specific user using item-based collaborative filtering\n",
    "user_id = 400\n",
    "precision = evaluate_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, k=10)\n",
    "\n",
    "if precision is not None:\n",
    "    print(f\"\\nPrecision@10 for User {user_id}: {precision:.4f}\")\n",
    "else:\n",
    "    print(f\"No test data for User {user_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Method Implementation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions: 74267\n",
      "Test interactions: 18567\n",
      "\n",
      "Top SVD-Based Recommendations for User 2:\n",
      "Artist ID: 3464, Artist: Counting Crows, Similarity Score: 2346.16\n",
      "Artist ID: 1089, Artist: Suede, Similarity Score: 1826.24\n",
      "Artist ID: 259, Artist: 9th Wonder, Similarity Score: 1581.01\n",
      "Artist ID: 153, Artist: De/Vision, Similarity Score: 1536.43\n",
      "Artist ID: 992, Artist: Chris Rea, Similarity Score: 1110.52\n",
      "Actual artists interacted by user 2: [59, 90]\n",
      "Recommended artists for user 2: [(3464, 'Counting Crows', 2346.1635801737975), (1089, 'Suede', 1826.2352731085477), (259, '9th Wonder', 1581.0064805606642), (153, 'De/Vision', 1536.4340448821988), (992, 'Chris Rea', 1110.5230835462432), (1496, 'Amsterdam Guitar Trio', 962.6347429798363), (469, 'Nick Carter', 947.2787227982989), (7594, 'Majek Fashek', 927.5537243285531), (222, 'Modest Mouse', 881.6089335976576), (4229, 'Адаптация Пчёл', 839.9796343081118)]\n",
      "Precision@K: 0.0\n",
      "Recall@K: 0.0\n",
      "F1@K: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure user_artists_cleaned has non-zero weights\n",
    "user_artists_cleaned = user_artists_cleaned[user_artists_cleaned['weight'] > 0]\n",
    "\n",
    "# Perform global train-test split\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verification\n",
    "print(f\"Train interactions: {train_data.shape[0]}\")\n",
    "print(f\"Test interactions: {test_data.shape[0]}\")\n",
    "\n",
    "# Function to get SVD-based recommendations\n",
    "def get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10, n_components=50):\n",
    "    # Apply SVD to the user-artist matrix\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    svd_matrix = svd.fit_transform(user_artist_matrix)\n",
    "    svd_components = svd.components_\n",
    "\n",
    "    # Reconstruct the user-artist interaction matrix\n",
    "    reconstructed_matrix = np.dot(svd_matrix, svd_components)\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # Ensure user_id is within the valid range (2 to 1892)\n",
    "    if user_id < 2 or user_id > user_artist_matrix.shape[0] + 1:\n",
    "        raise ValueError(f\"User ID {user_id} is out of bounds for the user_artist_matrix.\")\n",
    "    \n",
    "    # Get the user's interaction vector from the reconstructed matrix (adjust for zero-based index)\n",
    "    reconstructed_user_vector = reconstructed_matrix[user_id - 2]  # User IDs start at 2, so subtract 2\n",
    "    \n",
    "    # Iterate through all artists to recommend\n",
    "    for i, score in enumerate(reconstructed_user_vector):\n",
    "        # Check if the artist has been interacted with (score > 0) and if the artist ID is valid\n",
    "        if user_artist_matrix.iloc[user_id - 2, i] == 0:  # Ensure we only recommend non-interacted artists\n",
    "            artist_id = i  # The index of the artist in the matrix\n",
    "            if artist_id not in recommendations:\n",
    "                recommendations[artist_id] = score\n",
    "            else:\n",
    "                recommendations[artist_id] += score\n",
    "    \n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert artist IDs to names using the artist_id_to_name mapping\n",
    "    recommended_artists = [(artist_id, artist_id_to_name.get(artist_id, \"Unknown\"), score)\n",
    "                           for artist_id, score in sorted_recommendations[:top_n]]\n",
    "    \n",
    "    return recommended_artists\n",
    "\n",
    "# Function to evaluate SVD-based recommendations on test data\n",
    "def evaluate_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10, n_components=50):\n",
    "    recommended_artists = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n, n_components)\n",
    "\n",
    "    # Get the actual interacted artists from the test set\n",
    "    actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    # Extract recommended artist IDs from the recommendations list\n",
    "    recommended_artists_ids = [artist_id for artist_id, _, _ in recommended_artists]\n",
    "\n",
    "    # Precision at K\n",
    "    precision_at_k = precision_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                                     [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # Recall at K\n",
    "    recall_at_k = recall_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                               [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # F1 at K\n",
    "    f1_at_k = f1_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                        [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    return precision_at_k, recall_at_k, f1_at_k\n",
    "\n",
    "# Example: Get top 5 SVD-based recommendations for user with userID=2\n",
    "user_id = 2\n",
    "svd_recommendations = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=5)\n",
    "\n",
    "# Display SVD-based recommendations\n",
    "print(\"\\nTop SVD-Based Recommendations for User 2:\")\n",
    "for artist_id, artist_name, score in svd_recommendations:\n",
    "    print(f\"Artist ID: {artist_id}, Artist: {artist_name}, Similarity Score: {score:.2f}\")\n",
    "\n",
    "# Example: Evaluate recommendations for a user in the test set\n",
    "precision_at_k, recall_at_k, f1_at_k = evaluate_recommendations(user_id=2, \n",
    "                                                                user_artist_matrix=user_artist_matrix, \n",
    "                                                                artist_id_to_name=artist_id_to_name, \n",
    "                                                                top_n=10, \n",
    "                                                                n_components=50)\n",
    "\n",
    "# Print actual and recommended artists to debug\n",
    "actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "print(f\"Actual artists interacted by user {user_id}: {actual_artists}\")\n",
    "\n",
    "recommended_artists = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10)\n",
    "print(f\"Recommended artists for user {user_id}: {recommended_artists}\")\n",
    "\n",
    "print(f\"Precision@K: {precision_at_k}\")\n",
    "print(f\"Recall@K: {recall_at_k}\")\n",
    "print(f\"F1@K: {f1_at_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation Based On Similarity\n",
    "The data is very sparse, hecnce, metrics we were using before will likely 0 for most of the recommendations. Thus, we will evaluate our data using the average similarity score for the first 20 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
