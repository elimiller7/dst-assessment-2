{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "from scipy import sparse\n",
    "\n",
    "from GNNfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = '..'\n",
    "artists = pd.read_csv(os.path.join(cwd,'data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join(cwd,'data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join(cwd,'data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join(cwd,'data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join(cwd,'data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join(cwd,'data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_artists['userID'].unique()\n",
    "singleartistusers = [user for user in users if len(get_artists(user,user_artists)) == 1]\n",
    "singleartistusersdf = user_artists[user_artists['userID'].isin(singleartistusers)]\n",
    "user_artists_temp = user_artists[~user_artists['userID'].isin(singleartistusers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_artists_train, user_artists_test = train_test_split(user_artists_temp, test_size = 0.2, stratify = user_artists_temp['userID'], random_state = 47)\n",
    "\n",
    "user_artists_train = pd.concat([user_artists_train,singleartistusersdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taggedartists_test = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'inner')\n",
    "user_taggedartists_train = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'left', indicator = True)\n",
    "user_taggedartists_train = user_taggedartists_train[user_taggedartists_train['_merge'] == 'left_only'].drop(columns = ['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs = [user_artists_train,user_artists_test,user_taggedartists_train,user_taggedartists_test]\n",
    "dfs = [user_artists_train,user_artists_test,user_friends]\n",
    "\n",
    "filepath = os.path.join(cwd,'SheridanH','LightGCN','data','lastfm2')\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "\n",
    "for df in dfs:\n",
    "    df.to_csv(os.path.join(filepath,get_df_name(df, globals()) + '.txt'),sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjacency Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92828</th>\n",
       "      <td>2100</td>\n",
       "      <td>18725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92830</th>\n",
       "      <td>2100</td>\n",
       "      <td>18727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92831</th>\n",
       "      <td>2100</td>\n",
       "      <td>18728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92832</th>\n",
       "      <td>2100</td>\n",
       "      <td>18729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92833</th>\n",
       "      <td>2100</td>\n",
       "      <td>18730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74268 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  artistID\n",
       "0           2        51\n",
       "1           2        52\n",
       "2           2        53\n",
       "3           2        54\n",
       "6           2        57\n",
       "...       ...       ...\n",
       "92828    2100     18725\n",
       "92830    2100     18727\n",
       "92831    2100     18728\n",
       "92832    2100     18729\n",
       "92833    2100     18730\n",
       "\n",
       "[74268 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vertices = user_artists['userID'].unique()\n",
    "artist_vertices = artists['id'].unique()\n",
    "user_artist_edges = user_artists_train[['userID','artistID']]\n",
    "user_artist_edges = user_artist_edges.sort_values(by = ['userID','artistID'])\n",
    "user_artist_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(user_artist_edges['userID'])\n",
    "dst = list(user_artist_edges['artistID'])\n",
    "edges = [src,dst]\n",
    "\n",
    "num_users = int(max(user_vertices)) + 1\n",
    "num_artists = int(max(artist_vertices)) + 1\n",
    "\n",
    "interaction_matrix = np.zeros([num_users,num_artists])\n",
    "\n",
    "for src,dst in zip(edges[0],edges[1]):\n",
    "    interaction_matrix[src][dst] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['git', 'clone', 'https://github.com/gusye1234/LightGCN-PyTorch', '../SheridanH/LightGCN'], returncode=128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "repo_url = \"https://github.com/gusye1234/LightGCN-PyTorch\"\n",
    "clone_directory = \"../SheridanH/LightGCN\"\n",
    "\n",
    "subprocess.run([\"git\", \"clone\", repo_url, clone_directory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userID  artistID  weight\n",
      "0        2        51   13883\n",
      "1        2        52   11690\n",
      "2        2        53   11351\n",
      "3        2        54   10300\n",
      "6        2        57    5955\n",
      "7        2        58    4616\n",
      "9        2        60    4147\n",
      "10       2        61    3923\n",
      "12       2        63    3735\n",
      "13       2        64    3644\n",
      "    userID  artistID  weight\n",
      "4        2        55    8983\n",
      "5        2        56    6152\n",
      "8        2        59    4337\n",
      "11       2        62    3782\n",
      "27       2        78    2119\n",
      "34       2        85    1638\n",
      "41       2        92    1411\n",
      "46       2        97    1337\n",
      "47       2        98    1332\n",
      "48       2        99    1330\n"
     ]
    }
   ],
   "source": [
    "print(user_artists_train.sort_values(by=['userID','artistID']).iloc[:10])\n",
    "print(user_artists_test.sort_values(by=['userID','artistID']).iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dataset\n",
    "\n",
    "already has lastfm dataset defined but it is slightly different to ours, so we will add ours to dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "18745\n"
     ]
    }
   ],
   "source": [
    "print(max(users))\n",
    "artistlist = list(artists['id'].unique())\n",
    "print(max(artistlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import world\n",
    "from time import time\n",
    "\n",
    "code_to_write = '''\n",
    "class LastFM2(BasicDataset):\n",
    "    \"\"\"\n",
    "    Dataset type for pytorch\n",
    "    LastFM dataset 2\n",
    "    \"\"\"\n",
    "    def __init__(self, path=\"../data/lastfm2\"):\n",
    "        # train or test\n",
    "        cprint(\"loading [last fm]\")\n",
    "        self.mode_dict = {'train':0, \"test\":1}\n",
    "        self.mode    = self.mode_dict['train']\n",
    "        # self.n_users = 2100\n",
    "        # self.m_items = 18745\n",
    "        trainData = pd.read_table(join(path, 'user_artists_train.txt'), header=None)\n",
    "        print(trainData.head())\n",
    "        testData  = pd.read_table(join(path, 'user_artists_test.txt'), header=None)\n",
    "        print(testData.head())\n",
    "        trustNet  = pd.read_table(join(path, 'user_friends.txt'), header=None).to_numpy()\n",
    "        print(trustNet[:5])\n",
    "        trustNet -= 1\n",
    "        trainData-= 1\n",
    "        testData -= 1\n",
    "        self.trustNet  = trustNet\n",
    "        self.trainData = trainData\n",
    "        self.testData  = testData\n",
    "        self.trainUser = np.array(trainData[:][0])\n",
    "        self.trainUniqueUsers = np.unique(self.trainUser)\n",
    "        self.trainItem = np.array(trainData[:][1])\n",
    "        # self.trainDataSize = len(self.trainUser)\n",
    "        self.testUser  = np.array(testData[:][0])\n",
    "        self.testUniqueUsers = np.unique(self.testUser)\n",
    "        self.testItem  = np.array(testData[:][1])\n",
    "        self.Graph = None\n",
    "        print(f\"LastFm2 Sparsity : {(len(self.trainUser) + len(self.testUser))/self.n_users/self.m_items}\")\n",
    "        \n",
    "        # (users,users)\n",
    "        self.socialNet    = csr_matrix((np.ones(len(trustNet)), (trustNet[:,0], trustNet[:,1]) ), shape=(self.n_users,self.n_users))\n",
    "        # (users,items), bipartite graph\n",
    "        self.UserItemNet  = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem) ), shape=(self.n_users,self.m_items)) \n",
    "        \n",
    "        # pre-calculate\n",
    "        self._allPos = self.getUserPosItems(list(range(self.n_users)))\n",
    "        self.allNeg = []\n",
    "        allItems    = set(range(self.m_items))\n",
    "        for i in range(self.n_users):\n",
    "            pos = set(self._allPos[i])\n",
    "            neg = allItems - pos\n",
    "            self.allNeg.append(np.array(list(neg)))\n",
    "        self.__testDict = self.__build_test()\n",
    "\n",
    "    @property\n",
    "    def n_users(self):\n",
    "        return 2100\n",
    "    \n",
    "    @property\n",
    "    def m_items(self):\n",
    "        return 18745\n",
    "    \n",
    "    @property\n",
    "    def trainDataSize(self):\n",
    "        return len(self.trainUser)\n",
    "    \n",
    "    @property\n",
    "    def testDict(self):\n",
    "        return self.__testDict\n",
    "\n",
    "    @property\n",
    "    def allPos(self):\n",
    "        return self._allPos\n",
    "\n",
    "    def getSparseGraph(self):\n",
    "        if self.Graph is None:\n",
    "            user_dim = torch.LongTensor(self.trainUser)\n",
    "            item_dim = torch.LongTensor(self.trainItem)\n",
    "            \n",
    "            first_sub = torch.stack([user_dim, item_dim + self.n_users])\n",
    "            second_sub = torch.stack([item_dim+self.n_users, user_dim])\n",
    "            index = torch.cat([first_sub, second_sub], dim=1)\n",
    "            data = torch.ones(index.size(-1)).int()\n",
    "            self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            dense = self.Graph.to_dense()\n",
    "            D = torch.sum(dense, dim=1).float()\n",
    "            D[D==0.] = 1.\n",
    "            D_sqrt = torch.sqrt(D).unsqueeze(dim=0)\n",
    "            dense = dense/D_sqrt\n",
    "            dense = dense/D_sqrt.t()\n",
    "            index = dense.nonzero()\n",
    "            data  = dense[dense >= 1e-9]\n",
    "            assert len(index) == len(data)\n",
    "            self.Graph = torch.sparse.FloatTensor(index.t(), data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            self.Graph = self.Graph.coalesce().to(world.device)\n",
    "        return self.Graph\n",
    "\n",
    "    def __build_test(self):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            dict: {user: [items]}\n",
    "        \"\"\"\n",
    "        test_data = {}\n",
    "        for i, item in enumerate(self.testItem):\n",
    "            user = self.testUser[i]\n",
    "            if test_data.get(user):\n",
    "                test_data[user].append(item)\n",
    "            else:\n",
    "                test_data[user] = [item]\n",
    "        return test_data\n",
    "    \n",
    "    def getUserItemFeedback(self, users, items):\n",
    "        \"\"\"\n",
    "        users:\n",
    "            shape [-1]\n",
    "        items:\n",
    "            shape [-1]\n",
    "        return:\n",
    "            feedback [-1]\n",
    "        \"\"\"\n",
    "        # print(self.UserItemNet[users, items])\n",
    "        return np.array(self.UserItemNet[users, items]).astype('uint8').reshape((-1, ))\n",
    "    \n",
    "    def getUserPosItems(self, users):\n",
    "        posItems = []\n",
    "        for user in users:\n",
    "            posItems.append(self.UserItemNet[user].nonzero()[1])\n",
    "        return posItems\n",
    "    \n",
    "    def getUserNegItems(self, users):\n",
    "        negItems = []\n",
    "        for user in users:\n",
    "            negItems.append(self.allNeg[user])\n",
    "        return negItems\n",
    "            \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.trainUniqueUsers[index]\n",
    "        # return user_id and the positive items of the user\n",
    "        return user\n",
    "    \n",
    "    def switch2test(self):\n",
    "        \"\"\"\n",
    "        change dataset mode to offer test data to dataloader\n",
    "        \"\"\"\n",
    "        self.mode = self.mode_dict['test']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainUniqueUsers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../SheridanH/LightGCN/code/dataloader.py\", \"a\") as file:\n",
    "    file.write(code_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!cd ../SheridanH/LightGCN/code && python main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=2020 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
