{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Neural Networks, or GNNs, are a method of applying machine learning technology to graph structures, consisting of nodes, or vertices, connected by edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding The Task\n",
    "\n",
    "The goal of a recommender system is to try to predict which items a user will like, and then give them recommendations based on this. In this section, for our dataset, we will look at the goal of predicting whether or not a user will like an artist. To achieve this, we will create an 80-20 training-testing split of the data. We have seen that for most users, the `user_artist` dataset contains their top 50 artists, so we will take 40 of them for each user at random, and isolate the other 10 to use as testing data. We will then train a GNN on the 40 artists in the training dataset, and evaluate the model by seeing how it predicts the user will like the 10 artists in the testing data. If the model performs well on this target, then we could use the model to predict whether or not a user will like an artist not contained in their 50 artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "\n",
    "from GNNfuncs import *\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import GraphFrame\n",
    "import findspark\n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv(os.path.join('..','data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join('..','data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join('..','data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join('..','data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join('..','data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join('..','data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here to format the data to make it work better for the graph. Currently there is overlap in the name of the users, artists, and tags, since each is just designated an integer. If we were to add these as nodes of a graph we would not be able to distinguish between them, and so here we add the type of node to the front of the number, and save it all as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designations added\n"
     ]
    }
   ],
   "source": [
    "if user_artists['userID'][0] != 'user2':\n",
    "    user_artists['userID'] = 'user' + user_artists['userID'].astype(str) # Place 'user' before each userID \n",
    "    user_artists['artistID'] = 'artist' + user_artists['artistID'].astype(str) # Place 'artist' before each artistID\n",
    "    user_friends['userID'] = 'user' + user_friends['userID'].astype(str) # Place 'user' before each userID\n",
    "    user_friends['friendID'] = 'user' + user_friends['friendID'].astype(str) # Place 'user' before each userID\n",
    "    user_taggedartists['artistID'] = 'artist' + user_taggedartists['artistID'].astype(str) # Place 'artist' before each artistID\n",
    "    user_taggedartists['tagID'] = 'tag' + user_taggedartists['tagID'].astype(str) # Place 'tag' before each tagID\n",
    "    user_taggedartists['userID'] = 'user' + user_taggedartists['userID'].astype(str) # Place 'user' before each userID\n",
    "    artists['id'] = 'artist' + artists['id'].astype(str) # Place 'artist' before each artistID\n",
    "    tags['tagID'] = 'tag' + tags['tagID'].astype(str) # Place 'tag' before each tagID\n",
    "    print('Designations added')\n",
    "else:\n",
    "    print('Designations already present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing-Training Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to temporarily drop users with only 1 artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_artists['userID'].unique()\n",
    "singleartistusers = [user for user in users if len(get_artists(user,user_artists)) == 1]\n",
    "singleartistusersdf = user_artists[user_artists['userID'].isin(singleartistusers)]\n",
    "user_artists_temp = user_artists[~user_artists['userID'].isin(singleartistusers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 80-20 split, ensuring that the proportion of each artist is kept the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_artists_train, user_artists_test = train_test_split(user_artists_temp, test_size = 0.2, stratify = user_artists_temp['userID'], random_state = 47)\n",
    "\n",
    "user_artists_train = pd.concat([user_artists_train,singleartistusersdf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to make sure we remove the same artists from user_taggedartists, so that we don't have a user's tags for an artist that we want to test them on, as this would indicate interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taggedartists_test = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'inner')\n",
    "user_taggedartists_train = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'left', indicator = True)\n",
    "user_taggedartists_train = user_taggedartists_train[user_taggedartists_train['_merge'] == 'left_only'].drop(columns = ['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('..','SheridanH','data')\n",
    "for df in [user_artists_train,user_artists_test,user_taggedartists_train,user_taggedartists_test]:\n",
    "    df.to_csv(os.path.join(filepath,get_df_name(df, globals())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vertices and Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vertices\n",
    "user_vertices = pd.DataFrame(user_artists_train['userID'].unique(), columns = ['id']) # All users as nodes\n",
    "\n",
    "artist_vertices = pd.DataFrame(artists['id'].unique(), columns = [\"id\"]) # all artists as nodes\n",
    "\n",
    "tag_vertices = pd.DataFrame(tags['tagID'].unique(), columns = [\"id\"]) # all tags as nodes\n",
    "\n",
    "# Define edges\n",
    "user_artist_edges = user_artists_train.drop('weight', axis = 1).rename(columns = {'userID' : 'src', 'artistID' : 'dst'})\n",
    "user_artist_edges['type'] = 'listens' # user -> artist edges labelled 'listens'\n",
    "\n",
    "user_tag_edges = user_taggedartists_train.rename(columns = {'userID' : 'src', 'tagID' : 'dst'})\n",
    "for col in ['day','month','year','artistID']:\n",
    "    user_tag_edges = user_tag_edges.drop(col, axis = 1)\n",
    "user_tag_edges['type'] = 'tag_used' # user -> tag edges labelled 'tag_used'\n",
    "\n",
    "\n",
    "artist_tag_edges = user_taggedartists_train.rename(columns = {'artistID' : 'src', 'tagID' : 'dst'})\n",
    "for col in ['day','month','year','userID']:\n",
    "    artist_tag_edges = artist_tag_edges.drop(col, axis = 1)\n",
    "artist_tag_edges['type'] = 'tagged_as' # artist -> tag edges labelled 'tagged_as'\n",
    "\n",
    "user_user_edges = user_friends.rename(columns = {'userID' : 'src', 'friendID' : 'dst'})\n",
    "user_user_edges['type'] = 'friend' # friend <-> friends edges labelled 'friend'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartite Graph\n",
    "\n",
    "We start by making a graph using just the user-artist interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19524, 1) (74268, 3)\n"
     ]
    }
   ],
   "source": [
    "vertices = pd.concat([user_vertices,artist_vertices])\n",
    "edges = pd.concat([user_artist_edges])\n",
    "\n",
    "print(vertices.shape,edges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_path = r'C:\\Users\\Sheri\\AppData\\Local\\Programs\\Python\\Python311\\python.exe'  \n",
    "os.environ['PYSPARK_PYTHON'] = python_path\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = python_path\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GNN\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sheri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "graph = GraphFrame(spark.createDataFrame(vertices),spark.createDataFrame(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
