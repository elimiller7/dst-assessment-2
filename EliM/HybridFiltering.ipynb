{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hybrid Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 0: Theory\n",
    "Hybrid filtering is the combination of different recommendation techniques, with the goal of giving more accurate and meaningful recommendations. This is a way to benefit from the elements of the different techniques and limit the effect of their drawbacks. One approach to do so is combining collaborative and content-based filtering. Weighted hybridisation optimises a hyperparameter which determines the contribution from each method. Switching hybridisation chooses which method to use according to a chosen decision rule which depends on the data. Finally, mixed hybridisation gives recommendations which have been given by each of the different methods separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1: Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "artists = pd.read_csv(os.path.join('..','data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join('..','data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join('..','data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join('..','data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join('..','data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join('..','data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns from the Artists dataset\n",
    "artists_cleaned = artists.drop(columns=['url', 'pictureURL']).drop_duplicates(keep='first') \n",
    "\n",
    "# Drop the irrelevant columns in the Tags dataset\n",
    "tags_cleaned = tags.drop_duplicates(keep='first') \n",
    "\n",
    "# For the User-Artists dataset, we can filter out rows with a weight of 0, as they show no meaningful interaction\n",
    "user_artists_cleaned = user_artists[user_artists['weight'] > 0]\n",
    "user_artists_cleaned = user_artists_cleaned.drop_duplicates(keep='first') \n",
    "\n",
    "# Drop duplicates from the User-Tagged Artists Timestamps dataset\n",
    "user_taggedartists_timestamps_cleaned = user_taggedartists_timestamps.drop_duplicates(keep='first') \n",
    "\n",
    "# Convert timestamps from ms to datetime format\n",
    "user_taggedartists_timestamps_cleaned['timestamp'] = pd.to_datetime(user_taggedartists_timestamps_cleaned['timestamp'], unit='ms')\n",
    "\n",
    "# Drop duplicates from the User-Friends dataset\n",
    "user_friends_cleaned = user_friends.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"CollaborativeFilteringALS\").getOrCreate()\n",
    "\n",
    "# Convert cleaned pandas DataFrames to PySpark DataFrames\n",
    "artists_spark_df = spark.createDataFrame(artists_cleaned)\n",
    "user_artists_spark_df = spark.createDataFrame(user_artists_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 4492.4848\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|userID|recommendations                                                                                                               |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|3     |[{Hande Yener, 1.14}, {Ani DiFranco, 1.05}, {ムック, 1.0}, {Pleq, 1.0}, {Klaus Badelt, 0.98}]                                 |\n",
      "|5     |[{Beck, 1.09}, {Kings of Convenience, 1.08}, {Beirut, 1.06}, {The Smiths, 1.05}, {The White Stripes, 1.05}]                   |\n",
      "|6     |[{Brandy, 0.49}, {Danity Kane, 0.44}, {50 Cent, 0.44}, {B.o.B, 0.43}, {Joss Stone, 0.43}]                                     |\n",
      "|12    |[{Eminem, 1.57}, {Lenny Kravitz, 1.31}, {No Doubt, 1.24}, {Scooter, 1.24}, {Guano Apes, 1.2}]                                 |\n",
      "|13    |[{Eminem, 0.96}, {Lady Gaga, 0.92}, {Coldplay, 0.91}, {Kanye West, 0.91}, {Avril Lavigne, 0.91}]                              |\n",
      "|15    |[{Gnarls Barkley, 1.25}, {Stars of the Lid, 1.18}, {Yann Tiersen, 1.17}, {植松伸夫, 1.16}, {Boards of Canada, 1.14}]          |\n",
      "|16    |[{Aura Dione, 1.26}, {Basshunter, 1.19}, {Tiësto, 1.17}, {Scooter, 1.17}, {Ricky Martin, 1.16}]                               |\n",
      "|20    |[{Venetian Snares, 1.29}, {Beatsteaks, 1.23}, {Sick Puppies, 1.15}, {65daysofstatic, 1.14}, {The Asteroids Galaxy Tour, 1.13}]|\n",
      "|22    |[{Trivium, 1.21}, {Saosin, 1.2}, {Coma, 1.18}, {Finch, 1.17}, {Killwhitneydead, 1.17}]                                        |\n",
      "|26    |[{Converge, 1.22}, {Billie Holiday, 1.21}, {Frédéric Chopin, 1.17}, {Jamie Cullum, 1.17}, {Sepultura, 1.17}]                  |\n",
      "|27    |[{Eminem, 1.18}, {The Cranberries, 1.1}, {The Beatles, 1.09}, {System of a Down, 1.08}, {Muse, 1.07}]                         |\n",
      "|28    |[{Vangelis, 0.32}, {Orchestral Manoeuvres in the Dark, 0.31}, {Sting, 0.31}, {Camouflage, 0.31}, {Erasure, 0.31}]             |\n",
      "|31    |[{Eminem, 1.25}, {Blondie, 1.11}, {a-ha, 1.11}, {Soft Cell, 1.11}, {Erasure, 1.09}]                                           |\n",
      "|34    |[{Gnarls Barkley, 1.36}, {Ladytron, 1.32}, {Fleet Foxes, 1.29}, {Johnny Cash, 1.27}, {Manu Chao, 1.25}]                       |\n",
      "|40    |[{Guano Apes, 1.37}, {Drowning Pool, 1.35}, {L'Âme Immortelle, 1.3}, {Ill Niño, 1.21}, {DJ Krush, 1.16}]                      |\n",
      "|41    |[{Bruce Dickinson, 1.16}, {Sepultura, 1.15}, {Manowar, 1.14}, {Dio, 1.13}, {Judas Priest, 1.13}]                              |\n",
      "|43    |[{O.S.T.R., 1.18}, {Tori Amos, 1.13}, {Kanye West, 1.11}, {Sade, 1.1}, {Björk, 1.1}]                                          |\n",
      "|44    |[{Korn, 1.06}, {Faith No More, 1.06}, {Porcupine Tree, 1.06}, {Bob Dylan, 1.05}, {Danny Elfman, 1.04}]                        |\n",
      "|47    |[{Kelly Clarkson, 1.03}, {Glee Cast, 1.03}, {Lady Gaga, 1.03}, {Backstreet Boys, 1.03}, {Britney Spears, 1.03}]               |\n",
      "|48    |[{Eminem, 1.22}, {Roxette, 1.03}, {Cyndi Lauper, 1.02}, {Jay-Z, 1.02}, {Avril Lavigne, 1.01}]                                 |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time elapsed: 43.4763 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# ALS model setup for user-based collaborative filtering\n",
    "als = ALS(userCol=\"userID\", itemCol=\"artistID\", ratingCol=\"weight\", coldStartStrategy=\"drop\", implicitPrefs=True, regParam=1.0)\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% testing)\n",
    "train_data, test_data = user_artists_spark_df.randomSplit([0.8, 0.2], seed=27)\n",
    "\n",
    "# Fit the ALS model\n",
    "model = als.fit(train_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "rmse = predictions.withColumn(\"squared_error\", (F.col(\"prediction\") - F.col(\"weight\"))**2)\n",
    "rmse_value = rmse.select(F.sqrt(F.avg(\"squared_error\"))).first()[0]\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_value:.4f}\")\n",
    "\n",
    "# Generate recommendations\n",
    "user_recommendations = model.recommendForAllUsers(5)\n",
    "\n",
    "# Create a dictionary to map artistID to artistName\n",
    "artist_id_to_name = {row['id']: row['name'] for row in artists_spark_df.collect()}\n",
    "\n",
    "# Function to map artistID to artistName and round scores to 2 decimal places\n",
    "def map_recommendations(user_recommendations):\n",
    "    def map_row(row):\n",
    "        recommendations_with_names = [\n",
    "            (artist_id_to_name.get(rec[0], \"Unknown\"), round(rec[1], 2)) for rec in row['recommendations']\n",
    "        ]\n",
    "        return (row['userID'], recommendations_with_names)\n",
    "\n",
    "    mapped_recommendations = user_recommendations.rdd.map(map_row).toDF([\"userID\", \"recommendations\"])\n",
    "    return mapped_recommendations\n",
    "\n",
    "# Apply the artistID to name mapping function\n",
    "user_recommendations_with_names = map_recommendations(user_recommendations)\n",
    "\n",
    "# Show the final recommendations with artist names and rounded scores\n",
    "user_recommendations_with_names.show(truncate=False)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Time elapsed: {end_time - start_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
