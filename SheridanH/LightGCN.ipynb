{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from GNNfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = '..'\n",
    "artists = pd.read_csv(os.path.join(cwd,'data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join(cwd,'data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join(cwd,'data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join(cwd,'data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join(cwd,'data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join(cwd,'data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_artists['userID'].unique()\n",
    "singleartistusers = [user for user in users if len(get_artists(user,user_artists)) == 1]\n",
    "singleartistusersdf = user_artists[user_artists['userID'].isin(singleartistusers)]\n",
    "user_artists_temp = user_artists[~user_artists['userID'].isin(singleartistusers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "user_artists_train, user_artists_test = train_test_split(user_artists_temp, test_size = 0.2, stratify = user_artists_temp['userID'], random_state = 47)\n",
    "\n",
    "user_artists_train = pd.concat([user_artists_train,singleartistusersdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taggedartists_test = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'inner')\n",
    "user_taggedartists_train = user_taggedartists.merge(user_artists_test[['userID','artistID']], on = ['userID','artistID'], how = 'left', indicator = True)\n",
    "user_taggedartists_train = user_taggedartists_train[user_taggedartists_train['_merge'] == 'left_only'].drop(columns = ['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [user_artists_train,user_artists_test,user_friends]\n",
    "\n",
    "filepath = os.path.join(cwd,'data','GNN')\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "\n",
    "for df in dfs:\n",
    "    df.to_csv(os.path.join(filepath,get_df_name(df, globals()) + '.txt'),sep='\\t',header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the dataset\n",
    "\n",
    "already has lastfm dataset defined but it is slightly different to ours, so we will add ours to dataloader.py. This consists of adding it as a class to dataloader.py, done by duplicating and editing the already existing LastFM class. We then add an elif statement to register.py to register it, and finally add it to the `all_dataset` list in world.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users)\n",
    "artistlist = list(artists['id'].unique())\n",
    "print(artistlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_write = '''\n",
    "class LastFM2(BasicDataset):\n",
    "    \"\"\"\n",
    "    Dataset type for pytorch\n",
    "    LastFM dataset 2\n",
    "    \"\"\"\n",
    "    def __init__(self, path=\"../data/GNN\"):\n",
    "        # train or test\n",
    "        cprint(\"loading [last fm]\")\n",
    "        self.mode_dict = {'train':0, \"test\":1}\n",
    "        self.mode    = self.mode_dict['train']\n",
    "        # self.n_users = 2100\n",
    "        # self.m_items = 18745\n",
    "        trainData = pd.read_table(join(path, 'user_artists_train.txt'), header=None)\n",
    "        print(trainData.head())\n",
    "        testData  = pd.read_table(join(path, 'user_artists_test.txt'), header=None)\n",
    "        print(testData.head())\n",
    "        trustNet  = pd.read_table(join(path, 'user_friends.txt'), header=None).to_numpy()\n",
    "        print(trustNet[:5])\n",
    "        trustNet -= 1\n",
    "        trainData-= 1\n",
    "        testData -= 1\n",
    "        self.trustNet  = trustNet\n",
    "        self.trainData = trainData\n",
    "        self.testData  = testData\n",
    "        self.trainUser = np.array(trainData[:][0])\n",
    "        self.trainUniqueUsers = np.unique(self.trainUser)\n",
    "        self.trainItem = np.array(trainData[:][1])\n",
    "        # self.trainDataSize = len(self.trainUser)\n",
    "        self.testUser  = np.array(testData[:][0])\n",
    "        self.testUniqueUsers = np.unique(self.testUser)\n",
    "        self.testItem  = np.array(testData[:][1])\n",
    "        self.Graph = None\n",
    "        print(f\"LastFm2 Sparsity : {(len(self.trainUser) + len(self.testUser))/self.n_users/self.m_items}\")\n",
    "        \n",
    "        # (users,users)\n",
    "        self.socialNet    = csr_matrix((np.ones(len(trustNet)), (trustNet[:,0], trustNet[:,1]) ), shape=(self.n_users,self.n_users))\n",
    "        # (users,items), bipartite graph\n",
    "        self.UserItemNet  = csr_matrix((np.ones(len(self.trainUser)), (self.trainUser, self.trainItem) ), shape=(self.n_users,self.m_items)) \n",
    "        \n",
    "        # pre-calculate\n",
    "        self._allPos = self.getUserPosItems(list(range(self.n_users)))\n",
    "        self.allNeg = []\n",
    "        allItems    = set(range(self.m_items))\n",
    "        for i in range(self.n_users):\n",
    "            pos = set(self._allPos[i])\n",
    "            neg = allItems - pos\n",
    "            self.allNeg.append(np.array(list(neg)))\n",
    "        self.__testDict = self.__build_test()\n",
    "\n",
    "    @property\n",
    "    def n_users(self):\n",
    "        return 2100\n",
    "    \n",
    "    @property\n",
    "    def m_items(self):\n",
    "        return 18745\n",
    "    \n",
    "    @property\n",
    "    def trainDataSize(self):\n",
    "        return len(self.trainUser)\n",
    "    \n",
    "    @property\n",
    "    def testDict(self):\n",
    "        return self.__testDict\n",
    "\n",
    "    @property\n",
    "    def allPos(self):\n",
    "        return self._allPos\n",
    "\n",
    "    def getSparseGraph(self):\n",
    "        if self.Graph is None:\n",
    "            user_dim = torch.LongTensor(self.trainUser)\n",
    "            item_dim = torch.LongTensor(self.trainItem)\n",
    "            \n",
    "            first_sub = torch.stack([user_dim, item_dim + self.n_users])\n",
    "            second_sub = torch.stack([item_dim+self.n_users, user_dim])\n",
    "            index = torch.cat([first_sub, second_sub], dim=1)\n",
    "            data = torch.ones(index.size(-1)).int()\n",
    "            self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            dense = self.Graph.to_dense()\n",
    "            D = torch.sum(dense, dim=1).float()\n",
    "            D[D==0.] = 1.\n",
    "            D_sqrt = torch.sqrt(D).unsqueeze(dim=0)\n",
    "            dense = dense/D_sqrt\n",
    "            dense = dense/D_sqrt.t()\n",
    "            index = dense.nonzero()\n",
    "            data  = dense[dense >= 1e-9]\n",
    "            assert len(index) == len(data)\n",
    "            self.Graph = torch.sparse.FloatTensor(index.t(), data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n",
    "            self.Graph = self.Graph.coalesce().to(world.device)\n",
    "        return self.Graph\n",
    "\n",
    "    def __build_test(self):\n",
    "        \"\"\"\n",
    "        return:\n",
    "            dict: {user: [items]}\n",
    "        \"\"\"\n",
    "        test_data = {}\n",
    "        for i, item in enumerate(self.testItem):\n",
    "            user = self.testUser[i]\n",
    "            if test_data.get(user):\n",
    "                test_data[user].append(item)\n",
    "            else:\n",
    "                test_data[user] = [item]\n",
    "        return test_data\n",
    "    \n",
    "    def getUserItemFeedback(self, users, items):\n",
    "        \"\"\"\n",
    "        users:\n",
    "            shape [-1]\n",
    "        items:\n",
    "            shape [-1]\n",
    "        return:\n",
    "            feedback [-1]\n",
    "        \"\"\"\n",
    "        # print(self.UserItemNet[users, items])\n",
    "        return np.array(self.UserItemNet[users, items]).astype('uint8').reshape((-1, ))\n",
    "    \n",
    "    def getUserPosItems(self, users):\n",
    "        posItems = []\n",
    "        for user in users:\n",
    "            posItems.append(self.UserItemNet[user].nonzero()[1])\n",
    "        return posItems\n",
    "    \n",
    "    def getUserNegItems(self, users):\n",
    "        negItems = []\n",
    "        for user in users:\n",
    "            negItems.append(self.allNeg[user])\n",
    "        return negItems\n",
    "            \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = self.trainUniqueUsers[index]\n",
    "        # return user_id and the positive items of the user\n",
    "        return user\n",
    "    \n",
    "    def switch2test(self):\n",
    "        \"\"\"\n",
    "        change dataset mode to offer test data to dataloader\n",
    "        \"\"\"\n",
    "        self.mode = self.mode_dict['test']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trainUniqueUsers)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaderpath = os.path.join('..','scripts','LightGCN','dataloader.py')\n",
    "dataloader = open(dataloaderpath)\n",
    "\n",
    "if 'class LastFM2(BasicDataset)' not in dataloader.read():\n",
    "    with open(dataloaderpath,'a') as file:\n",
    "        file.write(code_to_write)\n",
    "        print('Class added.')\n",
    "else:\n",
    "    print('Class already present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultspath = os.path.join('..','scripts','LightGCN','results')\n",
    "if not os.path.exists(resultspath):\n",
    "    os.makedirs(resultspath)\n",
    "resultsfile = os.path.join(resultspath,'results.csv')\n",
    "if os.path.exists(resultsfile):\n",
    "    os.remove(resultsfile)\n",
    "pd.DataFrame(columns=['precision','recall','ndcg']).to_csv(resultsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is cpu, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      ">>SEED: 47\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.00235706955576828\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "Device used is cpu, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.00235706955576828\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\LightGCN\\dataloader.py:487: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00026567]), 'recall': array([0.00053135]), 'ndcg': array([0.00040668])}\n",
      "EPOCH[1/10] loss0.686-|Sample:0.79|\n",
      "EPOCH[2/10] loss0.660-|Sample:0.68|\n",
      "EPOCH[3/10] loss0.571-|Sample:0.79|\n",
      "EPOCH[4/10] loss0.446-|Sample:0.68|\n",
      "EPOCH[5/10] loss0.350-|Sample:0.78|\n",
      "EPOCH[6/10] loss0.296-|Sample:0.67|\n",
      "EPOCH[7/10] loss0.265-|Sample:0.78|\n",
      "EPOCH[8/10] loss0.241-|Sample:0.78|\n",
      "EPOCH[9/10] loss0.224-|Sample:0.68|\n",
      "EPOCH[10/10] loss0.211-|Sample:0.79|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.0642933]), 'recall': array([0.13117884]), 'ndcg': array([0.13391279])}\n",
      "EPOCH[11/10] loss0.199-|Sample:0.66|\n",
      "Total time taken: 79.41200017929077\n"
     ]
    }
   ],
   "source": [
    "%run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=10 --device=CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is cuda, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      ">>SEED: 47\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 4\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "Device used is cuda, with multicore: 0.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 4\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [20]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\LightGCN\\dataloader.py:487: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  self.Graph = torch.sparse.IntTensor(index, data, torch.Size([self.n_users+self.m_items, self.n_users+self.m_items]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00061105]), 'recall': array([0.00122801]), 'ndcg': array([0.00092211])}\n",
      "EPOCH[1/10] loss0.686-|Sample:0.67|\n",
      "EPOCH[2/10] loss0.661-|Sample:0.78|\n",
      "EPOCH[3/10] loss0.575-|Sample:0.77|\n",
      "EPOCH[4/10] loss0.451-|Sample:0.66|\n",
      "EPOCH[5/10] loss0.354-|Sample:0.77|\n",
      "EPOCH[6/10] loss0.298-|Sample:0.77|\n",
      "EPOCH[7/10] loss0.267-|Sample:0.65|\n",
      "EPOCH[8/10] loss0.243-|Sample:0.78|\n",
      "EPOCH[9/10] loss0.225-|Sample:0.66|\n",
      "EPOCH[10/10] loss0.211-|Sample:0.76|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.06259299]), 'recall': array([0.12805568]), 'ndcg': array([0.12743833])}\n",
      "EPOCH[11/10] loss0.200-|Sample:0.77|\n",
      "Total time taken: 16.980195999145508\n"
     ]
    }
   ],
   "source": [
    "%run -i \"../scripts/LightGCN/main.py\" --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=\"[20]\" --recdim=64 --epochs=10 --device=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>SEED: 47\n",
      "Device used is cuda.\n",
      "\u001b[0;30;43mCpp extension not loaded\u001b[0m\n",
      "\u001b[0;30;43mloading [last fm]\u001b[0m\n",
      "      0     1     2\n",
      "0   443   174   786\n",
      "1  1197   325   744\n",
      "2   826  2009    18\n",
      "3  1186   302   810\n",
      "4   586  4271  3625\n",
      "      0      1     2\n",
      "0  1639    176  1814\n",
      "1  1904    609   132\n",
      "2  1358  14094   378\n",
      "3  1086  12208  2658\n",
      "4  1559    300   107\n",
      "[[  2 275]\n",
      " [  2 428]\n",
      " [  2 515]\n",
      " [  2 761]\n",
      " [  2 831]]\n",
      "LastFm2 Sparsity : 0.002358317773628523\n",
      "===========config================\n",
      "{'A_n_fold': 100,\n",
      " 'A_split': False,\n",
      " 'bigdata': False,\n",
      " 'bpr_batch_size': 2048,\n",
      " 'decay': 0.0001,\n",
      " 'dropout': 0,\n",
      " 'keep_prob': 0.6,\n",
      " 'latent_dim_rec': 64,\n",
      " 'lightGCN_n_layers': 3,\n",
      " 'lr': 0.001,\n",
      " 'multicore': 0,\n",
      " 'pretrain': 0,\n",
      " 'test_u_batch_size': 100}\n",
      "cores for test: 8\n",
      "comment: lgn\n",
      "tensorboard: 1\n",
      "LOAD: 0\n",
      "Weight path: ./checkpoints\n",
      "Test Topks: [30]\n",
      "using bpr loss\n",
      "===========end===================\n",
      "\u001b[0;30;43muse NORMAL distribution initilizer\u001b[0m\n",
      "lgn is already to go(dropout:0)\n",
      "load and save to C:\\Users\\Sheri\\Documents\\GitHub\\dst-assessment-2\\scripts\\code\\checkpoints\\lgn-lastfm2-3-64.pth.tar\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.00074389]), 'recall': array([0.00236155]), 'ndcg': array([0.00142676])}\n",
      "EPOCH[1/10] loss0.686-|Sample:0.68|\n",
      "EPOCH[2/10] loss0.661-|Sample:0.83|\n",
      "EPOCH[3/10] loss0.575-|Sample:0.68|\n",
      "EPOCH[4/10] loss0.451-|Sample:0.83|\n",
      "EPOCH[5/10] loss0.354-|Sample:0.66|\n",
      "EPOCH[6/10] loss0.298-|Sample:0.67|\n",
      "EPOCH[7/10] loss0.267-|Sample:0.81|\n",
      "EPOCH[8/10] loss0.243-|Sample:0.67|\n",
      "EPOCH[9/10] loss0.225-|Sample:0.82|\n",
      "EPOCH[10/10] loss0.211-|Sample:0.66|\n",
      "\u001b[0;30;43m[TEST]\u001b[0m\n",
      "{'precision': array([0.05159405]), 'recall': array([0.15799934]), 'ndcg': array([0.14138036])}\n",
      "EPOCH[11/10] loss0.200-|Sample:0.81|\n",
      "Total time taken: 14.470257997512817\n"
     ]
    }
   ],
   "source": [
    "for ks in ['[10]','[20]','[30]']:\n",
    "    %run -i ../scripts/LightGCN/main.py --decay=1e-4 --lr=0.001 --layer=3 --seed=47 --dataset=\"lastfm2\" --topks=ks --recdim=64 --epochs=10 --device=GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LightGCN\n",
    "from register import dataset\n",
    "\n",
    "Recmodel = register.MODELS[world.model_name](world.config, dataset).to(world.device)\n",
    "checkpoint = torch.load('../scripts/code/checkpoints/lgn-lastfm2-3-64.pth.tar')\n",
    "Recmodel.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 2\n",
    "user_tensor = torch.tensor([user_id]).to(world.device)\n",
    "user_artist_test_list = get_artists(user_id, user_artists_test)\n",
    "\n",
    "for artist_id in user_artist_test_list:\n",
    "    artist_tensor = torch.tensor([artist_id]).to(world.device)\n",
    "    recommendation_score = Recmodel(user_tensor,artist_tensor)\n",
    "    print(f'For user {user_id}, artist {artist_id} is recommended with score {recommendation_score.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(os.path.join('..','scripts','LightGCN','results','results.csv'),index_col='Unnamed: 0')\n",
    "\n",
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "for column in results.columns:\n",
    "    plt.plot(results.index,results[column],'--',label=column,)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
