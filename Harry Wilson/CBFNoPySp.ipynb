{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing Content Based Filtering with No PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"/Users/harrywilson/Desktop/DataScienceToolbox/Assessment2Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.87625, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "file_path = f\"{base_directory}/artists.dat\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    result = chardet.detect(f.read(10000))  # Analyze the first 10KB\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_data(filename):\n",
    "    file_path = f\"{base_directory}/{filename}\"\n",
    "    return pd.read_csv(file_path, sep=\"\\t\", header=0)  # sep=\"\\t\" for tab-separated, header=0 means first row is the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "artists_file = os.path.join(base_directory, \"artists.dat\")\n",
    "tags_file = os.path.join(base_directory, \"tags.dat\")\n",
    "user_artists_file = os.path.join(base_directory, \"user_artists.dat\")\n",
    "user_taggedartists_file = os.path.join(base_directory, \"user_taggedartists.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "artists = pd.read_csv(artists_file, sep=\"\\t\", header=0)\n",
    "tags = pd.read_csv(tags_file, sep=\"\\t\", header=0, encoding=\"latin-1\")\n",
    "user_artists = pd.read_csv(user_artists_file, sep=\"\\t\", header=0)\n",
    "user_taggedartists = pd.read_csv(user_taggedartists_file, sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id               name                                         url  \\\n",
      "0   1       MALICE MIZER       http://www.last.fm/music/MALICE+MIZER   \n",
      "1   2    Diary of Dreams    http://www.last.fm/music/Diary+of+Dreams   \n",
      "2   3  Carpathian Forest  http://www.last.fm/music/Carpathian+Forest   \n",
      "3   4       Moi dix Mois       http://www.last.fm/music/Moi+dix+Mois   \n",
      "4   5        Bella Morte        http://www.last.fm/music/Bella+Morte   \n",
      "\n",
      "                                          pictureURL  \n",
      "0    http://userserve-ak.last.fm/serve/252/10808.jpg  \n",
      "1  http://userserve-ak.last.fm/serve/252/3052066.jpg  \n",
      "2  http://userserve-ak.last.fm/serve/252/40222717...  \n",
      "3  http://userserve-ak.last.fm/serve/252/54697835...  \n",
      "4  http://userserve-ak.last.fm/serve/252/14789013...  \n",
      "   tagID           tagValue\n",
      "0      1              metal\n",
      "1      2  alternative metal\n",
      "2      3          goth rock\n",
      "3      4        black metal\n",
      "4      5        death metal\n",
      "   userID  artistID  weight\n",
      "0       2        51   13883\n",
      "1       2        52   11690\n",
      "2       2        53   11351\n",
      "3       2        54   10300\n",
      "4       2        55    8983\n",
      "   userID  artistID  tagID  day  month  year\n",
      "0       2        52     13    1      4  2009\n",
      "1       2        52     15    1      4  2009\n",
      "2       2        52     18    1      4  2009\n",
      "3       2        52     21    1      4  2009\n",
      "4       2        52     41    1      4  2009\n"
     ]
    }
   ],
   "source": [
    "# Display a preview of the data\n",
    "print(artists.head())\n",
    "print(tags.head())\n",
    "print(user_artists.head())\n",
    "print(user_taggedartists.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artistID        artist_name  \\\n",
      "0         1       MALICE MIZER   \n",
      "1         2    Diary of Dreams   \n",
      "2         3  Carpathian Forest   \n",
      "3         4       Moi dix Mois   \n",
      "4         5        Bella Morte   \n",
      "\n",
      "                                                tags  \n",
      "0  [jrock, j-rock, weeabo, visual kei, better tha...  \n",
      "1  [gothic rock, darkwave, seen live, dark, vocal...  \n",
      "2  [saxophones, black metal, norwegian black meta...  \n",
      "3  [metal, bazarov, j-rock, visual kei, gothic ja...  \n",
      "4  [gothic rock, darkwave, covers, deathrock, got...  \n"
     ]
    }
   ],
   "source": [
    "# Join user_taggedartists with tags for tag information\n",
    "artist_tags_df = user_taggedartists.merge(tags, on=\"tagID\", how=\"inner\")\n",
    "\n",
    "# Join the result with artists to get artist details and tag names\n",
    "artist_tags_info_df = artist_tags_df.merge(artists, left_on=\"artistID\", right_on=\"id\")\n",
    "\n",
    "# Aggregate tags for each artist into a list and remove duplicates\n",
    "artist_profiles_df = (\n",
    "    artist_tags_info_df.groupby([\"artistID\", \"name\"])[\"tagValue\"]\n",
    "    .apply(lambda tags: list(set(tags)))  # Remove duplicates and collect tags\n",
    "    .reset_index()\n",
    "    .rename(columns={\"name\": \"artist_name\", \"tagValue\": \"tags\"})\n",
    ")\n",
    "\n",
    "# Display artist profiles\n",
    "print(artist_profiles_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywilson/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   artistID        artist_name  '80s  'n'  -  --  ---  --------  ---king  \\\n",
      "0         1       MALICE MIZER     0    0  0   0    0         0        0   \n",
      "1         2    Diary of Dreams     0    0  0   0    0         0        0   \n",
      "2         3  Carpathian Forest     0    0  0   0    0         0        0   \n",
      "3         4       Moi dix Mois     0    0  0   0    0         0        0   \n",
      "4         5        Bella Morte     0    0  0   0    0         0        0   \n",
      "\n",
      "   -angels  ...  zombie  zombieland  zone  zoocore  zooey  zorn  zornish  ztt  \\\n",
      "0        0  ...       0           0     0        0      0     0        0    0   \n",
      "1        0  ...       0           0     0        0      0     0        0    0   \n",
      "2        0  ...       0           0     0        0      0     0        0    0   \n",
      "3        0  ...       0           0     0        0      0     0        0    0   \n",
      "4        0  ...       0           0     0        0      0     0        0    0   \n",
      "\n",
      "   zu  Ã¤rzte  \n",
      "0   0      0  \n",
      "1   0      0  \n",
      "2   0      0  \n",
      "3   0      0  \n",
      "4   0      0  \n",
      "\n",
      "[5 rows x 7954 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert tags into strings (required for CountVectorizer)\n",
    "artist_profiles_df[\"tag_text\"] = artist_profiles_df[\"tags\"].apply(lambda tags: \" \".join(tags))\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x:x.split())\n",
    "\n",
    "\n",
    "# Fit and transform the tag_text column\n",
    "tag_vectors = vectorizer.fit_transform(artist_profiles_df[\"tag_text\"])\n",
    "\n",
    "# Convert the sparse matrix to a dense DataFrame for better visualization\n",
    "tag_vectors_df = pd.DataFrame(tag_vectors.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add artist information for context\n",
    "vectorized_artist_profiles_df = pd.concat(\n",
    "    [artist_profiles_df[[\"artistID\", \"artist_name\"]], tag_vectors_df], axis=1\n",
    ")\n",
    "\n",
    "# Display vectorized features\n",
    "print(vectorized_artist_profiles_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   80s  alternative  dance  electronic  female  hip  hop  \\\n",
      "artist_name                                                                \n",
      "MALICE MIZER       0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Diary of Dreams    0.0          0.0    0.0    0.486981     0.0  0.0  0.0   \n",
      "Carpathian Forest  0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Moi dix Mois       0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Bella Morte        0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "\n",
      "                   indie      live  love     metal  new  pop  post  punk  \\\n",
      "artist_name                                                                \n",
      "MALICE MIZER         0.0  0.000000   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "Diary of Dreams      0.0  0.558006   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "Carpathian Forest    0.0  0.000000   0.0  1.000000  0.0  0.0   0.0   0.0   \n",
      "Moi dix Mois         0.0  0.000000   0.0  0.832639  0.0  0.0   0.0   0.0   \n",
      "Bella Morte          0.0  0.000000   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "\n",
      "                       rock      seen  songs  the  vocalists  \n",
      "artist_name                                                   \n",
      "MALICE MIZER       1.000000  0.000000    0.0  0.0        0.0  \n",
      "Diary of Dreams    0.347505  0.575082    0.0  0.0        0.0  \n",
      "Carpathian Forest  0.000000  0.000000    0.0  0.0        0.0  \n",
      "Moi dix Mois       0.553816  0.000000    0.0  0.0        0.0  \n",
      "Bella Morte        1.000000  0.000000    0.0  0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use TF-IDF to encode tags into numerical vectors\n",
    "tfidf = TfidfVectorizer(max_features=20)  # Limit to 10 features for simplicity\n",
    "artist_tag_matrix = tfidf.fit_transform(artist_profiles_df[\"tag_text\"])\n",
    "\n",
    "# Convert the matrix to a DataFrame for easier use\n",
    "artist_features = pd.DataFrame(\n",
    "    artist_tag_matrix.toarray(), \n",
    "    index=artist_profiles_df[\"artist_name\"], \n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "print(artist_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   80s  alternative  dance  electronic  female  hip  hop  \\\n",
      "artist_name                                                                \n",
      "MALICE MIZER       0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Diary of Dreams    0.0          0.0    0.0    0.486981     0.0  0.0  0.0   \n",
      "Carpathian Forest  0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Moi dix Mois       0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "Bella Morte        0.0          0.0    0.0    0.000000     0.0  0.0  0.0   \n",
      "\n",
      "                   indie      live  love     metal  new  pop  post  punk  \\\n",
      "artist_name                                                                \n",
      "MALICE MIZER         0.0  0.000000   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "Diary of Dreams      0.0  0.558006   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "Carpathian Forest    0.0  0.000000   0.0  1.000000  0.0  0.0   0.0   0.0   \n",
      "Moi dix Mois         0.0  0.000000   0.0  0.832639  0.0  0.0   0.0   0.0   \n",
      "Bella Morte          0.0  0.000000   0.0  0.000000  0.0  0.0   0.0   0.0   \n",
      "\n",
      "                       rock      seen  songs  the  vocalists  \n",
      "artist_name                                                   \n",
      "MALICE MIZER       1.000000  0.000000    0.0  0.0        0.0  \n",
      "Diary of Dreams    0.347505  0.639188    0.0  0.0        0.0  \n",
      "Carpathian Forest  0.000000  0.000000    0.0  0.0        0.0  \n",
      "Moi dix Mois       0.553816  0.000000    0.0  0.0        0.0  \n",
      "Bella Morte        1.000000  0.000000    0.0  0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply MinMaxScaler to normalize the feature vectors\n",
    "scaler = MinMaxScaler()\n",
    "scaled_artist_features = pd.DataFrame(\n",
    "    scaler.fit_transform(artist_features),\n",
    "    index=artist_features.index,\n",
    "    columns=artist_features.columns\n",
    ")\n",
    "\n",
    "# Display the scaled features\n",
    "print(scaled_artist_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             artistID_1      artistID_2  similarity\n",
      "0          MALICE MIZER      Apollo 440    0.501864\n",
      "1          MALICE MIZER       LOSTFREEQ    0.293470\n",
      "2          MALICE MIZER         Epstein    0.350454\n",
      "3          MALICE MIZER       Blackfoot    1.000000\n",
      "4          MALICE MIZER  Stealers Wheel    0.563057\n",
      "...                 ...             ...         ...\n",
      "34471620      LOSTFREEQ    Oz Alchemist    0.384612\n",
      "34472286      LOSTFREEQ      Apollo 440    0.498530\n",
      "34474005  Ciccone Youth    Oz Alchemist    0.379009\n",
      "34474006  Ciccone Youth      Apollo 440    0.407239\n",
      "34480745     Apollo 440    Oz Alchemist    0.745619\n",
      "\n",
      "[17238166 rows x 3 columns]\n",
      "             artistID_1   artistID_2  similarity\n",
      "6287985            ÐÑÑÐ°          M2M         1.0\n",
      "2357660       Lacrimosa       Hunter         1.0\n",
      "29318593      Vitamin C          M2M         1.0\n",
      "17474620  Handsome Furs  Paper Route         1.0\n",
      "17164325         Realms           ä¼ä½°         1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the scaled features to a sparse matrix\n",
    "scaled_features_sparse = csr_matrix(scaled_artist_features.values)\n",
    "\n",
    "# Compute pairwise cosine similarities (sparse matrix version)\n",
    "cosine_similarities_sparse = cosine_similarity(scaled_features_sparse, dense_output=False)\n",
    "\n",
    "# Extract non-zero similarity values (only upper triangle to avoid duplicates)\n",
    "artist_indices = cosine_similarities_sparse.nonzero()\n",
    "similarities = cosine_similarities_sparse.data\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "similarities_df = pd.DataFrame({\n",
    "    \"artistID_1\": artist_indices[0],\n",
    "    \"artistID_2\": artist_indices[1],\n",
    "    \"similarity\": similarities\n",
    "})\n",
    "\n",
    "# Filter out self-similarities and duplicate pairs\n",
    "similarities_df = similarities_df[similarities_df[\"artistID_1\"] < similarities_df[\"artistID_2\"]]\n",
    "\n",
    "# Optionally map indices back to artist names\n",
    "similarities_df[\"artistID_1\"] = similarities_df[\"artistID_1\"].map(lambda x: scaled_artist_features.index[x])\n",
    "similarities_df[\"artistID_2\"] = similarities_df[\"artistID_2\"].map(lambda x: scaled_artist_features.index[x])\n",
    "\n",
    "# Display the top 5 results\n",
    "print(similarities_df)\n",
    "print(similarities_df.sort_values(by=\"similarity\", ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m user_artist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(user_artists, artists, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martistID\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martistID\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 2: Join user interactions with artist similarity data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m user_recommendations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m      9\u001b[0m     user_artist_df,\n\u001b[1;32m     10\u001b[0m     similarities_df,\n\u001b[1;32m     11\u001b[0m     left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martistID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martistID_1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Step 3: Group by userID and artistID_2, calculate the average similarity\u001b[39;00m\n\u001b[1;32m     16\u001b[0m user_recommendations_agg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     17\u001b[0m     user_recommendations\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martistID_2\u001b[39m\u001b[38;5;124m\"\u001b[39m], as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39magg(avg_similarity\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:148\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 148\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    149\u001b[0m         left,\n\u001b[1;32m    150\u001b[0m         right,\n\u001b[1;32m    151\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    152\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    153\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    154\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    155\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    156\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    157\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    158\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    159\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    160\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:741\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    733\u001b[0m (\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m    737\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[1;32m    743\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1401\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1397\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1398\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1399\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1400\u001b[0m     ):\n\u001b[0;32m-> 1401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Step 1: Join user interactions with artist details\n",
    "user_artist_df = pd.merge(user_artists, artists, left_on=\"artistID\", right_on=\"id\")[[\"userID\", \"artistID\"]]\n",
    "\n",
    "# Step 2: Join user interactions with artist similarity data\n",
    "user_recommendations = pd.merge(\n",
    "    user_artist_df,\n",
    "    similarities_df,\n",
    "    left_on=\"artistID\",\n",
    "    right_on=\"artistID_1\"\n",
    ")\n",
    "\n",
    "# Step 3: Group by userID and artistID_2, calculate the average similarity\n",
    "user_recommendations_agg = (\n",
    "    user_recommendations\n",
    "    .groupby([\"userID\", \"artistID_2\"], as_index=False)\n",
    "    .agg(avg_similarity=(\"similarity\", \"mean\"))\n",
    ")\n",
    "\n",
    "# Step 4: Sort recommendations by userID and average similarity\n",
    "user_recommendations_sorted = user_recommendations_agg.sort_values(by=[\"userID\", \"avg_similarity\"], ascending=[True, False])\n",
    "\n",
    "# Display the top 50 recommendations\n",
    "print(user_recommendations_sorted.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userID             artistID_2  avg_similarity\n",
      "8         3       Antonio Banderas        1.000000\n",
      "15        3              Bakkushan        1.000000\n",
      "46        3            Electrovamp        1.000000\n",
      "56        3                Grenada        1.000000\n",
      "74        3          KT Wanderlust        1.000000\n",
      "79        3  Les Rythmes Digitales        1.000000\n",
      "85        3              Magic Box        1.000000\n",
      "88        3           Michael Mind        1.000000\n",
      "93        3               Monolith        1.000000\n",
      "94        3            Moonbootica        1.000000\n",
      "95        3                Moondog        1.000000\n",
      "96        3              Mr. Vegas        1.000000\n",
      "111       3        PlÃ¡cido Domingo        1.000000\n",
      "114       3            Rex the Dog        1.000000\n",
      "133       3          Steve Angello        1.000000\n",
      "147       3               Tim Berg        1.000000\n",
      "158       3                  athas        1.000000\n",
      "162       3                  ravex        1.000000\n",
      "32        3           Culture Beat        0.940972\n",
      "69        3            Inner Place        0.918176\n",
      "134       3             Steve Aoki        0.918176\n",
      "145       3          Thomas Anders        0.912233\n",
      "5         3                Ameerah        0.904757\n",
      "110       3        Platinum Blonde        0.874294\n",
      "135       3           Technotronic        0.853486\n",
      "37        3            Destin Road        0.851502\n",
      "126       3                  Snap!        0.836289\n",
      "33        3                 D:Ream        0.815361\n",
      "9         3               Arsenium        0.808381\n",
      "26        3           Chiara Iezzi        0.808381\n",
      "27        3        Chris Salvatore        0.808381\n",
      "28        3           Christian TV        0.808381\n",
      "52        3                   Gala        0.808381\n",
      "76        3    Kids in the Kitchen        0.808381\n",
      "82        3                  Lorie        0.808381\n",
      "115       3        Robin Skouteris        0.808381\n",
      "124       3                Shannon        0.808381\n",
      "164       3                  sifow        0.808381\n",
      "122       3            Sean Ensign        0.774076\n",
      "127       3                   Sono        0.772855\n",
      "44        3                 E-Type        0.770413\n",
      "1         3                 80kidz        0.757078\n",
      "4         3              Alter Ego        0.757078\n",
      "10        3      Astral Projection        0.757078\n",
      "14        3            Bag Raiders        0.757078\n",
      "17        3          Benassi Bros.        0.757078\n",
      "18        3                  Benga        0.757078\n",
      "22        3  Bodies Without Organs        0.757078\n",
      "30        3       Claude VonStroke        0.757078\n",
      "41        3                   Dj.M        0.757078\n"
     ]
    }
   ],
   "source": [
    "# Convert the artistID columns to the same data type (str is safer in this case)\n",
    "user_artists[\"artistID\"] = user_artists[\"artistID\"].astype(str)\n",
    "artists[\"id\"] = artists[\"id\"].astype(str)\n",
    "similarities_df[\"artistID_1\"] = similarities_df[\"artistID_1\"].astype(str)\n",
    "similarities_df[\"artistID_2\"] = similarities_df[\"artistID_2\"].astype(str)\n",
    "\n",
    "# Step 1: Join user interactions with artist details\n",
    "user_artist_df = pd.merge(user_artists, artists, left_on=\"artistID\", right_on=\"id\")[[\"userID\", \"artistID\"]]\n",
    "\n",
    "# Step 2: Join user interactions with artist similarity data\n",
    "user_recommendations = pd.merge(\n",
    "    user_artist_df,\n",
    "    similarities_df,\n",
    "    left_on=\"artistID\",\n",
    "    right_on=\"artistID_1\"\n",
    ")\n",
    "\n",
    "# Step 3: Group by userID and artistID_2, calculate the average similarity\n",
    "user_recommendations_agg = (\n",
    "    user_recommendations\n",
    "    .groupby([\"userID\", \"artistID_2\"], as_index=False)\n",
    "    .agg(avg_similarity=(\"similarity\", \"mean\"))\n",
    ")\n",
    "\n",
    "# Step 4: Sort recommendations by userID and average similarity\n",
    "user_recommendations_sorted = user_recommendations_agg.sort_values(by=[\"userID\", \"avg_similarity\"], ascending=[True, False])\n",
    "\n",
    "# Display the top 50 recommendations\n",
    "print(user_recommendations_sorted.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userID artistID_2       artist_name  avg_similarity\n",
      "0    2100      12012  Foxes In Fiction        0.699911\n",
      "1    2100       1997        Dragonland        0.337469\n",
      "2    2100        999    Thompson Twins        0.138429\n"
     ]
    }
   ],
   "source": [
    "# Input a user ID\n",
    "input_user_id = 2100\n",
    "\n",
    "# Step 1: Get artists the user has already interacted with\n",
    "interacted_artists = user_artists[user_artists[\"userID\"] == input_user_id][\"artistID\"].tolist()\n",
    "\n",
    "# Step 2: Generate recommendations for the user\n",
    "user_recommendations_filtered = (\n",
    "    user_artist_df[user_artist_df[\"userID\"] == input_user_id]  # Filter interactions for the input user\n",
    "    .merge(similarities_df, left_on=\"artistID\", right_on=\"artistID_1\")  # Join with similarities\n",
    ")\n",
    "\n",
    "# Step 3: Exclude already interacted artists\n",
    "user_recommendations_filtered = user_recommendations_filtered[\n",
    "    ~user_recommendations_filtered[\"artistID_2\"].isin(interacted_artists)\n",
    "]\n",
    "\n",
    "# Step 4: Group by userID and artistID_2, and calculate the average similarity\n",
    "user_recommendations_agg = (\n",
    "    user_recommendations_filtered\n",
    "    .groupby([\"userID\", \"artistID_2\"], as_index=False)\n",
    "    .agg(avg_similarity=(\"similarity\", \"mean\"))\n",
    "    .sort_values(by=\"avg_similarity\", ascending=False)  # Sort by similarity\n",
    ")\n",
    "\n",
    "# Step 5: Add artist names to the recommendations\n",
    "user_recommendations_with_names = (\n",
    "    user_recommendations_agg\n",
    "    .merge(artists, left_on=\"artistID_2\", right_on=\"id\", how=\"inner\")  # Add artist names\n",
    "    [[\"userID\", \"artistID_2\", \"name\", \"avg_similarity\"]]  # Select relevant columns\n",
    "    .rename(columns={\"name\": \"artist_name\"})  # Rename the artist name column\n",
    "    .sort_values(by=\"avg_similarity\", ascending=False)  # Sort again just in case\n",
    ")\n",
    "\n",
    "# Display the top 10 recommendations\n",
    "print(user_recommendations_with_names.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
