{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "artists = pd.read_csv(os.path.join('..','data','artists.dat'), delimiter='\\t')\n",
    "tags = pd.read_csv(os.path.join('..','data','tags.dat'), delimiter='\\t',encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv(os.path.join('..','data','user_artists.dat'), delimiter='\\t')\n",
    "user_friends = pd.read_csv(os.path.join('..','data','user_friends.dat'), delimiter='\\t')\n",
    "user_taggedartists_timestamps = pd.read_csv(os.path.join('..','data','user_taggedartists-timestamps.dat'), delimiter='\\t')\n",
    "user_taggedartists = pd.read_csv(os.path.join('..','data','user_taggedartists.dat'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92834 entries, 0 to 92833\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   userID    92834 non-null  int64\n",
      " 1   artistID  92834 non-null  int64\n",
      " 2   weight    92834 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.1 MB\n",
      "Cleaned User-Artists dataset: None    userID  artistID  weight\n",
      "0       2        51   13883\n",
      "1       2        52   11690\n",
      "2       2        53   11351\n",
      "3       2        54   10300\n",
      "4       2        55    8983\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant columns from the Artists dataset\n",
    "artists_cleaned = artists.drop(columns=['url', 'pictureURL']).drop_duplicates(keep='first') \n",
    "\n",
    "# Drop the irrelevant columns in the Tags dataset\n",
    "tags_cleaned = tags.drop_duplicates(keep='first') \n",
    "\n",
    "# For the User-Artists dataset, we can filter out rows with a weight of 0, as they show no meaningful interaction\n",
    "# user_artists_cleaned = user_artists[user_artists['weight'] > 0]\n",
    "user_artists_cleaned = user_artists.drop_duplicates(keep='first') \n",
    "\n",
    "# Drop duplicates from the User-Tagged Artists Timestamps dataset\n",
    "user_taggedartists_timestamps_cleaned = user_taggedartists_timestamps.drop_duplicates(keep='first') \n",
    "\n",
    "# Convert timestamps from ms to datetime format\n",
    "user_taggedartists_timestamps_cleaned['timestamp'] = pd.to_datetime(user_taggedartists_timestamps_cleaned['timestamp'], unit='ms')\n",
    "\n",
    "# Drop duplicates from the User-Friends dataset\n",
    "user_friends_cleaned = user_friends.drop_duplicates(keep='first') \n",
    "\n",
    "# # Output cleaned datasets for inspection\n",
    "# print(\"Cleaned Artists dataset:\", artists_cleaned.info(), artists_cleaned.head())\n",
    "# print(\"Cleaned Tags dataset:\", tags_cleaned.info(), tags_cleaned.head())\n",
    "# print(\"Cleaned User-Artists dataset:\", user_artists_cleaned.info(), user_artists_cleaned.head())\n",
    "# print(\"Cleaned User-Tagged Artists Timestamps dataset:\", user_taggedartists_timestamps_cleaned.info(), user_taggedartists_timestamps_cleaned.head())\n",
    "# print(\"Cleaned User-Friends dataset:\", user_friends_cleaned.info(), user_friends_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map artistID to artistName\n",
    "artist_id_to_name = dict(zip(artists['id'], artists['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train-Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions: 74267\n",
      "Test interactions: 18567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure user_artists_cleaned has non-zero weights\n",
    "user_artists_cleaned = user_artists_cleaned[user_artists_cleaned['weight'] > 0]\n",
    "\n",
    "# Perform global train-test split\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verification\n",
    "print(f\"Train interactions: {train_data.shape[0]}\")\n",
    "print(f\"Test interactions: {test_data.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Implementation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 74267\n",
      "Test data size: 18567\n",
      "Training data for user 2:\n",
      "artistID\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "5        0.0\n",
      "        ... \n",
      "18741    0.0\n",
      "18742    0.0\n",
      "18743    0.0\n",
      "18744    0.0\n",
      "18745    0.0\n",
      "Name: 2, Length: 17632, dtype: float64\n",
      "Test data for user 2:\n",
      "artistID\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "5        0.0\n",
      "        ... \n",
      "18741    0.0\n",
      "18742    0.0\n",
      "18743    0.0\n",
      "18744    0.0\n",
      "18745    0.0\n",
      "Name: 2, Length: 17632, dtype: float64\n",
      "Top User-Based Recommendations for User 2:\n",
      "Artist ID: 289, Artist: Britney Spears, Similarity Score: 20.67\n",
      "Artist ID: 288, Artist: Rihanna, Similarity Score: 20.10\n",
      "Artist ID: 295, Artist: Beyoncé, Similarity Score: 16.92\n",
      "Artist ID: 292, Artist: Christina Aguilera, Similarity Score: 16.73\n",
      "Artist ID: 300, Artist: Katy Perry, Similarity Score: 15.50\n",
      "Training data for user 2:\n",
      "artistID\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "5        0.0\n",
      "        ... \n",
      "18741    0.0\n",
      "18742    0.0\n",
      "18743    0.0\n",
      "18744    0.0\n",
      "18745    0.0\n",
      "Name: 2, Length: 17632, dtype: float64\n",
      "Test data for user 2:\n",
      "artistID\n",
      "1        0.0\n",
      "2        0.0\n",
      "3        0.0\n",
      "4        0.0\n",
      "5        0.0\n",
      "        ... \n",
      "18741    0.0\n",
      "18742    0.0\n",
      "18743    0.0\n",
      "18744    0.0\n",
      "18745    0.0\n",
      "Name: 2, Length: 17632, dtype: float64\n",
      "Precision@K: 0.0\n",
      "Recall@K: 0.0\n",
      "F1@K: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to get user-based recommendations\n",
    "def get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=10, train_matrix=None, test_matrix=None):\n",
    "    # Print the current train and test data used for this run\n",
    "    print(f\"Training data for user {user_id}:\")\n",
    "    print(train_matrix.loc[user_id])  # Training data for the specific user\n",
    "    print(f\"Test data for user {user_id}:\")\n",
    "    print(test_matrix.loc[user_id])  # Test data for the specific user\n",
    "\n",
    "    # Check if the user_id exists in user_similarity_df\n",
    "    if user_id not in user_similarity_df.columns:\n",
    "        raise ValueError(f\"user_id {user_id} not found in the user_similarity_df columns\")\n",
    "    \n",
    "    # Get the most similar users (excluding the user itself)\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]\n",
    "\n",
    "    recommendations = {}\n",
    "    for similar_user in similar_users:\n",
    "        # Get the artists this similar user has interacted with (non-zero values)\n",
    "        interacted_artists = user_artist_matrix.loc[similar_user][user_artist_matrix.loc[similar_user] > 0].index.tolist()\n",
    "\n",
    "        for artist in interacted_artists:\n",
    "            # Only consider artists the target user has not interacted with\n",
    "            if artist not in user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist():\n",
    "                # Add the artist to recommendations with a score (using the scaled similarity as a weight)\n",
    "                if artist not in recommendations:\n",
    "                    recommendations[artist] = user_similarity_df[user_id][similar_user]\n",
    "                else:\n",
    "                    # Add the weight of similarity to the current score\n",
    "                    recommendations[artist] += user_similarity_df[user_id][similar_user]\n",
    "\n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Convert artist IDs to names and prepare the final list with IDs, names, and scores\n",
    "    recommended_artists = [(artist, artist_id_to_name.get(artist, \"Unknown\"), score) for artist, score in sorted_recommendations[:top_n]]\n",
    "\n",
    "    return recommended_artists\n",
    "\n",
    "# Global train-test split (ensure this is applied once at the start)\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verify the train-test splits\n",
    "print(f\"Train data size: {train_data.shape[0]}\")\n",
    "print(f\"Test data size: {test_data.shape[0]}\")\n",
    "\n",
    "# Example: Get top 5 user-based recommendations for user with userID=2\n",
    "user_id = 2\n",
    "user_based_recommendations = get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=5, train_matrix=train_matrix, test_matrix=test_matrix)\n",
    "\n",
    "# Display user-based recommendations in the required format\n",
    "print(\"Top User-Based Recommendations for User 2:\")\n",
    "for artist_id, artist_name, score in user_based_recommendations:\n",
    "    print(f\"Artist ID: {artist_id}, Artist: {artist_name}, Similarity Score: {score:.2f}\")\n",
    "\n",
    "# Function to evaluate recommendations on test data\n",
    "def evaluate_recommendations(user_id, user_similarity_df_train, train_matrix, test_matrix, artist_id_to_name, top_n=10):\n",
    "    recommended_artists = get_user_based_recommendations(user_id, user_similarity_df_train, train_matrix, artist_id_to_name, top_n, train_matrix, test_matrix)\n",
    "\n",
    "    # Get the actual interacted artists from the test set\n",
    "    actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    # Extract recommended artist IDs from the recommendations list\n",
    "    recommended_artists_ids = [artist_id for artist_id, _, _ in recommended_artists]\n",
    "\n",
    "    # Precision at K\n",
    "    precision_at_k = precision_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                                     [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # Recall at K\n",
    "    recall_at_k = recall_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                               [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # F1 at K\n",
    "    f1_at_k = f1_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                        [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    return precision_at_k, recall_at_k, f1_at_k\n",
    "\n",
    "# Example: Evaluate recommendations for a user in the test set\n",
    "precision_at_k, recall_at_k, f1_at_k = evaluate_recommendations(user_id=2, \n",
    "                                                                user_similarity_df_train=user_similarity_df_train, \n",
    "                                                                train_matrix=train_matrix, \n",
    "                                                                test_matrix=test_matrix, \n",
    "                                                                artist_id_to_name=artist_id_to_name, \n",
    "                                                                top_n=10)\n",
    "\n",
    "print(f\"Precision@K: {precision_at_k}\")\n",
    "print(f\"Recall@K: {recall_at_k}\")\n",
    "print(f\"F1@K: {f1_at_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.0        17584\n",
      "2382.0         1\n",
      "2119.0         1\n",
      "1990.0         1\n",
      "1972.0         1\n",
      "1948.0         1\n",
      "1868.0         1\n",
      "1792.0         1\n",
      "1740.0         1\n",
      "1638.0         1\n",
      "1594.0         1\n",
      "1559.0         1\n",
      "1553.0         1\n",
      "1519.0         1\n",
      "1438.0         1\n",
      "1411.0         1\n",
      "1407.0         1\n",
      "1373.0         1\n",
      "1363.0         1\n",
      "1342.0         1\n",
      "1337.0         1\n",
      "1332.0         1\n",
      "1330.0         1\n",
      "2120.0         1\n",
      "2397.0         1\n",
      "13883.0        1\n",
      "2547.0         1\n",
      "11690.0        1\n",
      "11351.0        1\n",
      "10300.0        1\n",
      "8983.0         1\n",
      "6152.0         1\n",
      "5955.0         1\n",
      "4616.0         1\n",
      "4147.0         1\n",
      "3923.0         1\n",
      "3782.0         1\n",
      "3735.0         1\n",
      "3644.0         1\n",
      "3579.0         1\n",
      "3312.0         1\n",
      "3301.0         1\n",
      "2927.0         1\n",
      "2720.0         1\n",
      "2686.0         1\n",
      "2654.0         1\n",
      "2619.0         1\n",
      "2584.0         1\n",
      "1315.0         1\n",
      "Name: count, dtype: int64\n",
      "2\n",
      "0.0       17630\n",
      "4337.0        1\n",
      "1471.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_matrix.loc[user_id].value_counts())\n",
    "print(test_matrix.loc[user_id].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test data is extremely sparse, with a large number of zeroes. This is significantly affecting the performance of our recommendations, hence, we need to use different methods to overcome this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based Implementation Testing - EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a user-artist interaction matrix\n",
    "user_artist_matrix = user_artists_cleaned.pivot(index='userID', columns='artistID', values='weight')\n",
    "user_artist_matrix = user_artist_matrix.fillna(0)\n",
    "\n",
    "# Compute cosine similarity between items (artists in this case)\n",
    "item_similarity = cosine_similarity(user_artist_matrix.T)  # Transpose to compute similarity between artists\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=user_artist_matrix.columns, columns=user_artist_matrix.columns)\n",
    "\n",
    "# Function to get item-based recommendations for a user\n",
    "def get_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, top_n=10):\n",
    "    if user_id not in user_artist_matrix.index:\n",
    "        raise ValueError(f\"user_id {user_id} not found in user_artist_matrix\")\n",
    "    \n",
    "    # Get the artists the user has interacted with (non-zero values)\n",
    "    interacted_artists = user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist()\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # For each artist the user has interacted with, find similar artists\n",
    "    for artist in interacted_artists:\n",
    "        similar_artists = item_similarity_df[artist].sort_values(ascending=False).index[1:]  # Exclude the artist itself\n",
    "        \n",
    "        for similar_artist in similar_artists:\n",
    "            if similar_artist not in user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist():\n",
    "                if similar_artist not in recommendations:\n",
    "                    recommendations[similar_artist] = item_similarity_df[artist][similar_artist]\n",
    "                else:\n",
    "                    recommendations[similar_artist] += item_similarity_df[artist][similar_artist]\n",
    "    \n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert artist IDs to names using artist_id_to_name\n",
    "    recommended_artists = [(artist_id_to_name.get(artist_id, \"Unknown\"), score) for artist_id, score in sorted_recommendations[:top_n]]\n",
    "    return recommended_artists\n",
    "\n",
    "# Precision@K for a single user\n",
    "def precision_at_k_single_user(recommended_artists, actual_artists, k):\n",
    "    recommended_artists_k = [artist for artist, _ in recommended_artists[:k]]\n",
    "    relevant_items = set(recommended_artists_k).intersection(set(actual_artists))\n",
    "    \n",
    "    if k == 0: \n",
    "        return 0\n",
    "    \n",
    "    return len(relevant_items) / k\n",
    "\n",
    "# Function to create a train-test split for each user (80% train, 20% test)\n",
    "def get_train_test_data(user_artist_matrix, user_id, test_size=0.2):\n",
    "    user_data = user_artist_matrix.loc[user_id]\n",
    "    non_zero_interactions = user_data[user_data > 0]\n",
    "    \n",
    "    train_data, test_data = train_test_split(non_zero_interactions.index, test_size=test_size)\n",
    "    \n",
    "    train_data = user_artist_matrix.loc[user_id, train_data]\n",
    "    test_data = user_artist_matrix.loc[user_id, test_data]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Evaluate Precision@K for a single user using train-test split\n",
    "def evaluate_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, k=10):\n",
    "    # Get train and test data for the user\n",
    "    train_data, test_data = get_train_test_data(user_artist_matrix, user_id)\n",
    "    \n",
    "    if len(test_data) == 0:\n",
    "        print(f\"User {user_id} has no interactions in the test set.\")\n",
    "        return None\n",
    "    \n",
    "    # Convert test data artist IDs to names\n",
    "    test_data_artist_names = [artist_id_to_name.get(artist_id, \"Unknown\") for artist_id in test_data.tolist()]\n",
    "    \n",
    "    print(f\"Test data for User {user_id}: {test_data_artist_names}\")\n",
    "    \n",
    "    # Get item-based recommendations for the user\n",
    "    recommendations = get_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, top_n=k)\n",
    "    \n",
    "    print(f\"Recommended artists for User {user_id}: {recommendations}\")\n",
    "    \n",
    "    recommended_artists = [artist for artist, _ in recommendations]\n",
    "    \n",
    "    # Precision@K evaluation\n",
    "    precision = precision_at_k_single_user(recommendations, test_data_artist_names, k)\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data for User 400: ['Enigma', 'Pleq & Chihiro', 'Café Del Mar', 'Prefab Sprout', 'Napalm Death', 'Icehouse', 'Cock Robin', 'ABC', 'Talk Talk', 'Alicia Keys']\n",
      "Recommended artists for User 400: [('The Pussycat Dolls', 6.075895826180479), ('Lily Allen', 5.7880441242910905), ('Natasha Bedingfield', 5.588535556689219), ('Jordin Sparks', 5.248566112199366), ('Gwen Stefani', 5.240362225570055), ('Cascada', 4.9372139515057025), ('Cheryl Cole', 4.824498405678474), ('Karl Wolf', 4.709049898458179), ('Outlandish', 4.709049898458179), ('Cameron Cartio', 4.709049898458179)]\n",
      "\n",
      "Precision@10 for User 400: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluate Precision@K for a specific user using item-based collaborative filtering\n",
    "user_id = 400\n",
    "precision = evaluate_item_based_recommendations(user_id, item_similarity_df, user_artist_matrix, artist_id_to_name, k=10)\n",
    "\n",
    "if precision is not None:\n",
    "    print(f\"\\nPrecision@10 for User {user_id}: {precision:.4f}\")\n",
    "else:\n",
    "    print(f\"No test data for User {user_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Method Implementation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interactions: 74267\n",
      "Test interactions: 18567\n",
      "\n",
      "Top SVD-Based Recommendations for User 2:\n",
      "Artist ID: 3464, Artist: Counting Crows, Similarity Score: 2346.16\n",
      "Artist ID: 1089, Artist: Suede, Similarity Score: 1826.24\n",
      "Artist ID: 259, Artist: 9th Wonder, Similarity Score: 1581.01\n",
      "Artist ID: 153, Artist: De/Vision, Similarity Score: 1536.43\n",
      "Artist ID: 992, Artist: Chris Rea, Similarity Score: 1110.52\n",
      "Actual artists interacted by user 2: [59, 90]\n",
      "Recommended artists for user 2: [(3464, 'Counting Crows', 2346.1635801737975), (1089, 'Suede', 1826.2352731085477), (259, '9th Wonder', 1581.0064805606642), (153, 'De/Vision', 1536.4340448821988), (992, 'Chris Rea', 1110.5230835462432), (1496, 'Amsterdam Guitar Trio', 962.6347429798363), (469, 'Nick Carter', 947.2787227982989), (7594, 'Majek Fashek', 927.5537243285531), (222, 'Modest Mouse', 881.6089335976576), (4229, 'Адаптация Пчёл', 839.9796343081118)]\n",
      "Precision@K: 0.0\n",
      "Recall@K: 0.0\n",
      "F1@K: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure user_artists_cleaned has non-zero weights\n",
    "user_artists_cleaned = user_artists_cleaned[user_artists_cleaned['weight'] > 0]\n",
    "\n",
    "# Perform global train-test split\n",
    "train_data, test_data = train_test_split(user_artists_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test matrices (copy the original user_artist_matrix)\n",
    "train_matrix = user_artist_matrix.copy()\n",
    "test_matrix = user_artist_matrix.copy()\n",
    "\n",
    "# Set all non-train interactions in the train matrix to 0\n",
    "train_matrix.loc[:, :] = 0\n",
    "for row in train_data.itertuples(index=False):\n",
    "    train_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Set all non-test interactions in the test matrix to 0\n",
    "test_matrix.loc[:, :] = 0\n",
    "for row in test_data.itertuples(index=False):\n",
    "    test_matrix.loc[row.userID, row.artistID] = row.weight\n",
    "\n",
    "# Verification\n",
    "print(f\"Train interactions: {train_data.shape[0]}\")\n",
    "print(f\"Test interactions: {test_data.shape[0]}\")\n",
    "\n",
    "# Function to get SVD-based recommendations\n",
    "def get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10, n_components=50):\n",
    "    # Apply SVD to the user-artist matrix\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    svd_matrix = svd.fit_transform(user_artist_matrix)\n",
    "    svd_components = svd.components_\n",
    "\n",
    "    # Reconstruct the user-artist interaction matrix\n",
    "    reconstructed_matrix = np.dot(svd_matrix, svd_components)\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # Ensure user_id is within the valid range (2 to 1892)\n",
    "    if user_id < 2 or user_id > user_artist_matrix.shape[0] + 1:\n",
    "        raise ValueError(f\"User ID {user_id} is out of bounds for the user_artist_matrix.\")\n",
    "    \n",
    "    # Get the user's interaction vector from the reconstructed matrix (adjust for zero-based index)\n",
    "    reconstructed_user_vector = reconstructed_matrix[user_id - 2]  # User IDs start at 2, so subtract 2\n",
    "    \n",
    "    # Iterate through all artists to recommend\n",
    "    for i, score in enumerate(reconstructed_user_vector):\n",
    "        # Check if the artist has been interacted with (score > 0) and if the artist ID is valid\n",
    "        if user_artist_matrix.iloc[user_id - 2, i] == 0:  # Ensure we only recommend non-interacted artists\n",
    "            artist_id = i  # The index of the artist in the matrix\n",
    "            if artist_id not in recommendations:\n",
    "                recommendations[artist_id] = score\n",
    "            else:\n",
    "                recommendations[artist_id] += score\n",
    "    \n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Convert artist IDs to names using the artist_id_to_name mapping\n",
    "    recommended_artists = [(artist_id, artist_id_to_name.get(artist_id, \"Unknown\"), score)\n",
    "                           for artist_id, score in sorted_recommendations[:top_n]]\n",
    "    \n",
    "    return recommended_artists\n",
    "\n",
    "# Function to evaluate SVD-based recommendations on test data\n",
    "def evaluate_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10, n_components=50):\n",
    "    recommended_artists = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n, n_components)\n",
    "\n",
    "    # Get the actual interacted artists from the test set\n",
    "    actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "\n",
    "    # Extract recommended artist IDs from the recommendations list\n",
    "    recommended_artists_ids = [artist_id for artist_id, _, _ in recommended_artists]\n",
    "\n",
    "    # Precision at K\n",
    "    precision_at_k = precision_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                                     [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # Recall at K\n",
    "    recall_at_k = recall_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                               [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    # F1 at K\n",
    "    f1_at_k = f1_score([1 if artist in actual_artists else 0 for artist in recommended_artists_ids],\n",
    "                        [1] * len(recommended_artists_ids), average='micro')\n",
    "\n",
    "    return precision_at_k, recall_at_k, f1_at_k\n",
    "\n",
    "# Example: Get top 5 SVD-based recommendations for user with userID=2\n",
    "user_id = 2\n",
    "svd_recommendations = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=5)\n",
    "\n",
    "# Display SVD-based recommendations\n",
    "print(\"\\nTop SVD-Based Recommendations for User 2:\")\n",
    "for artist_id, artist_name, score in svd_recommendations:\n",
    "    print(f\"Artist ID: {artist_id}, Artist: {artist_name}, Similarity Score: {score:.2f}\")\n",
    "\n",
    "# Example: Evaluate recommendations for a user in the test set\n",
    "precision_at_k, recall_at_k, f1_at_k = evaluate_recommendations(user_id=2, \n",
    "                                                                user_artist_matrix=user_artist_matrix, \n",
    "                                                                artist_id_to_name=artist_id_to_name, \n",
    "                                                                top_n=10, \n",
    "                                                                n_components=50)\n",
    "\n",
    "# Print actual and recommended artists to debug\n",
    "actual_artists = test_matrix.loc[user_id][test_matrix.loc[user_id] > 0].index.tolist()\n",
    "print(f\"Actual artists interacted by user {user_id}: {actual_artists}\")\n",
    "\n",
    "recommended_artists = get_svd_recommendations(user_id, user_artist_matrix, artist_id_to_name, top_n=10)\n",
    "print(f\"Recommended artists for user {user_id}: {recommended_artists}\")\n",
    "\n",
    "print(f\"Precision@K: {precision_at_k}\")\n",
    "print(f\"Recall@K: {recall_at_k}\")\n",
    "print(f\"F1@K: {f1_at_k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation Based On Similarity\n",
    "The data is very sparse, hecnce, metrics we were using before will likely 0 for most of the recommendations. Thus, we will evaluate our data using the average similarity score for the first 20 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering - ROUGH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "............\n",
    "\n",
    "............\n",
    "\n",
    "............\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based Implementation\n",
    "EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artistID  1      2      3      4      5      6      7      8      9      \\\n",
      "userID                                                                    \n",
      "2           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "5           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2095        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2096        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2097        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2099        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2100        0.0    0.0  408.0    0.0    0.0  404.0    0.0    0.0    0.0   \n",
      "\n",
      "artistID  10     ...  18736  18737  18738  18739  18740  18741  18742  18743  \\\n",
      "userID           ...                                                           \n",
      "2           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "5           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "6           0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2095        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2096        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2097        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2099        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2100        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "artistID  18744  18745  \n",
      "userID                  \n",
      "2           0.0    0.0  \n",
      "3           0.0    0.0  \n",
      "4           0.0    0.0  \n",
      "5           0.0    0.0  \n",
      "6           0.0    0.0  \n",
      "...         ...    ...  \n",
      "2095        0.0    0.0  \n",
      "2096        0.0    0.0  \n",
      "2097        0.0    0.0  \n",
      "2099        0.0    0.0  \n",
      "2100        0.0    0.0  \n",
      "\n",
      "[1892 rows x 17632 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a user-artist interaction matrix using the user_artists_cleaned dataset\n",
    "user_artist_matrix = user_artists_cleaned.pivot(index='userID', columns='artistID', values='weight')\n",
    "\n",
    "# Fill NaN values with 0s (assuming binary or implicit feedback, i.e., 1 for interaction, 0 for no interaction)\n",
    "user_artist_matrix = user_artist_matrix.fillna(0)\n",
    "\n",
    "print(user_artist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID      2     3         4         5         6         7         8     \\\n",
      "userID                                                                     \n",
      "2       1.000000   0.0  0.144786  0.028692  0.007016  0.030219  0.008964   \n",
      "3       0.000000   1.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4       0.144786   0.0  1.000000  0.081193  0.006609  0.000000  0.000000   \n",
      "5       0.028692   0.0  0.081193  1.000000  0.000000  0.000000  0.000000   \n",
      "6       0.007016   0.0  0.006609  0.000000  1.000000  0.012713  0.018881   \n",
      "\n",
      "userID  9         10        11    ...      2090      2091      2092      2093  \\\n",
      "userID                            ...                                           \n",
      "2        0.0  0.000000  0.021267  ...  0.000000  0.043405  0.000000  0.004625   \n",
      "3        0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "4        0.0  0.009072  0.013407  ...  0.000000  0.000000  0.003776  0.006178   \n",
      "5        0.0  0.169078  0.004639  ...  0.010993  0.000000  0.205141  0.000000   \n",
      "6        0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "userID      2094  2095      2096      2097      2099  2100  \n",
      "userID                                                      \n",
      "2       0.001585   0.0  0.000956  0.082134  0.000000   0.0  \n",
      "3       0.000000   0.0  0.000000  0.000000  0.000318   0.0  \n",
      "4       0.000000   0.0  0.045125  0.659085  0.000000   0.0  \n",
      "5       0.000000   0.0  0.204557  0.119133  0.000000   0.0  \n",
      "6       0.000000   0.0  0.000000  0.000000  0.000000   0.0  \n",
      "\n",
      "[5 rows x 1892 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute the cosine similarity between users based on the user-artist matrix\n",
    "user_similarity = cosine_similarity(user_artist_matrix)\n",
    "\n",
    "# Convert the similarity into a DataFrame for easy inspection\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_artist_matrix.index, columns=user_artist_matrix.index)\n",
    "\n",
    "# Display a portion of the user similarity matrix\n",
    "print(user_similarity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1892 entries, 2 to 2100\n",
      "Columns: 1892 entries, 2 to 2100\n",
      "dtypes: float64(1892)\n",
      "memory usage: 27.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(user_similarity_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top User-Based Recommendations for User 2:\n",
      "Artist: Britney Spears, Similarity Score: 20.67060160796395\n",
      "Artist: Rihanna, Similarity Score: 20.100492212155483\n",
      "Artist: Beyoncé, Similarity Score: 16.91877858902918\n",
      "Artist: Christina Aguilera, Similarity Score: 16.72997456813588\n",
      "Artist: Katy Perry, Similarity Score: 15.502101456105809\n"
     ]
    }
   ],
   "source": [
    "def get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=10):\n",
    "    # Check if the user_id exists in user_similarity_df\n",
    "    if user_id not in user_similarity_df.columns:\n",
    "        raise ValueError(f\"user_id {user_id} not found in the user_similarity_df columns\")\n",
    "    \n",
    "    # Get the most similar users (excluding the user itself)\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False).index[1:]\n",
    "\n",
    "    recommendations = {}\n",
    "    for similar_user in similar_users:\n",
    "        # Get the artists this similar user has interacted with (non-zero values)\n",
    "        interacted_artists = user_artist_matrix.loc[similar_user][user_artist_matrix.loc[similar_user] > 0].index.tolist()\n",
    "\n",
    "        for artist in interacted_artists:\n",
    "            # Only consider artists the target user has not interacted with\n",
    "            if artist not in user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist():\n",
    "                # Add the artist to recommendations with a score (using the similarity as a weight)\n",
    "                if artist not in recommendations:\n",
    "                    recommendations[artist] = user_similarity_df[user_id][similar_user]\n",
    "                else:\n",
    "                    # Add the weight of similarity to the current score\n",
    "                    recommendations[artist] += user_similarity_df[user_id][similar_user]\n",
    "\n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Convert artist IDs to names using artist_id_to_name\n",
    "    recommended_artists = [(artist_id_to_name.get(artist_id, \"Unknown\"), score) for artist_id, score in sorted_recommendations[:top_n]]\n",
    "\n",
    "    return recommended_artists\n",
    "\n",
    "# Example: Get top 5 user-based recommendations for user with userID=2\n",
    "user_id = 2\n",
    "user_based_recommendations = get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=5)\n",
    "\n",
    "# Display user-based recommendations\n",
    "print(\"Top User-Based Recommendations for User 2:\")\n",
    "for artist_name, score in user_based_recommendations:\n",
    "    print(f\"Artist: {artist_name}, Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top User-Based Recommendations for User 400:\n",
      "Artist: Paramore, Similarity Score: 27.93375176214605\n",
      "Artist: The Pussycat Dolls, Similarity Score: 26.832268337698526\n",
      "Artist: Glee Cast, Similarity Score: 26.344246561820096\n",
      "Artist: Taylor Swift, Similarity Score: 26.107307429903695\n",
      "Artist: Mariah Carey, Similarity Score: 24.392060204745587\n"
     ]
    }
   ],
   "source": [
    "# Example: Get top 5 user-based recommendations for user with userID=500\n",
    "user_id = 400\n",
    "user_based_recommendations = get_user_based_recommendations(user_id, user_similarity_df, user_artist_matrix, artist_id_to_name, top_n=5)\n",
    "\n",
    "# Display user-based recommendations\n",
    "print(\"Top User-Based Recommendations for User 400:\")\n",
    "for artist_name, score in user_based_recommendations:\n",
    "    print(f\"Artist: {artist_name}, Similarity Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based Implementation\n",
    "EXPLANATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artistID  1        2      3      4        5         6         7         8      \\\n",
      "artistID                                                                        \n",
      "1           1.0  0.00000    0.0    0.0  0.00000  0.000000  0.008784  0.032075   \n",
      "2           0.0  1.00000    0.0    0.0  0.20774  0.000000  0.010696  0.000000   \n",
      "3           0.0  0.00000    1.0    0.0  0.00000  0.205607  0.000000  0.000000   \n",
      "4           0.0  0.00000    0.0    1.0  0.00000  0.000000  0.019742  0.049547   \n",
      "5           0.0  0.20774    0.0    0.0  1.00000  0.000000  0.042728  0.000000   \n",
      "\n",
      "artistID     9         10     ...  18736  18737  18738  18739  18740  18741  \\\n",
      "artistID                      ...                                             \n",
      "1         0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2         0.102094  0.387653  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "3         0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "4         0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "5         0.190713  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "artistID  18742  18743  18744  18745  \n",
      "artistID                              \n",
      "1           0.0    0.0    0.0    0.0  \n",
      "2           0.0    0.0    0.0    0.0  \n",
      "3           0.0    0.0    0.0    0.0  \n",
      "4           0.0    0.0    0.0    0.0  \n",
      "5           0.0    0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 17632 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Create the user-artist interaction matrix\n",
    "user_artist_matrix = user_artists_cleaned.pivot(index='userID', columns='artistID', values='weight')\n",
    "\n",
    "# Fill NaN values with 0s (assuming binary or implicit feedback, i.e., 1 for interaction, 0 for no interaction)\n",
    "user_artist_matrix = user_artist_matrix.fillna(0)\n",
    "\n",
    "# Compute the cosine similarity between artists (transpose the matrix to compare artists)\n",
    "artist_similarity = cosine_similarity(user_artist_matrix.T)  # Transpose to compare artists (columns)\n",
    "\n",
    "# Convert the similarity matrix into a DataFrame for easy inspection\n",
    "artist_similarity_df = pd.DataFrame(artist_similarity, index=user_artist_matrix.columns, columns=user_artist_matrix.columns)\n",
    "\n",
    "# Display a portion of the artist similarity matrix\n",
    "print(artist_similarity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Item-Based Recommendations for User 2:\n",
      "Artist ID: 74, Artist: Basia, Similarity Score: 24.969685892158687\n",
      "Artist ID: 92, Artist: Vitamin Z, Similarity Score: 24.969685892158687\n",
      "Artist ID: 79, Artist: Fiction Factory, Similarity Score: 24.969685892158687\n",
      "Artist ID: 87, Artist: Deacon Blue, Similarity Score: 24.969685892158687\n",
      "Artist ID: 60, Artist: Matt Bianco, Similarity Score: 23.96847243980373\n",
      "Artist ID: 78, Artist: The Adventures, Similarity Score: 23.92260549725451\n",
      "Artist ID: 94, Artist: Ministry of Sound, Similarity Score: 23.767422523708806\n",
      "Artist ID: 52, Artist: Morcheeba, Similarity Score: 23.504036925175043\n",
      "Artist ID: 54, Artist: Hooverphonic, Similarity Score: 23.422779414621985\n",
      "Artist ID: 73, Artist: Café Del Mar, Similarity Score: 23.332277541517254\n"
     ]
    }
   ],
   "source": [
    "def get_item_based_recommendations(user_id, user_artist_matrix, artist_similarity_df, artist_id_to_name, top_n=10):\n",
    "    # Get the artists the user has interacted with (non-zero values)\n",
    "    interacted_artists = user_artist_matrix.loc[user_id][user_artist_matrix.loc[user_id] > 0].index.tolist()\n",
    "    \n",
    "    recommendations = {}\n",
    "    for artist in interacted_artists:\n",
    "        # Get the most similar artists to the ones the user interacted with\n",
    "        similar_artists = artist_similarity_df[artist].sort_values(ascending=False).index[1:]  # Exclude the artist itself\n",
    "\n",
    "        for similar_artist in similar_artists:\n",
    "            # Add the similar artist to recommendations with a score (using the similarity as a weight)\n",
    "            if similar_artist not in recommendations:\n",
    "                recommendations[similar_artist] = artist_similarity_df[artist][similar_artist]\n",
    "            else:\n",
    "                recommendations[similar_artist] += artist_similarity_df[artist][similar_artist]\n",
    "\n",
    "    # Sort recommendations by score (highest first)\n",
    "    sorted_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Convert artist IDs to names using artist_id_to_name\n",
    "    recommended_artists = [(artist_id, artist_id_to_name.get(artist_id, \"Unknown\"), score) \n",
    "                           for artist_id, score in sorted_recommendations[:top_n]]\n",
    "\n",
    "    return recommended_artists\n",
    "\n",
    "# Example: Get top 10 item-based recommendations for user with userID=2\n",
    "user_id = 2  # Change this to the desired user ID\n",
    "item_based_recommendations = get_item_based_recommendations(user_id, user_artist_matrix, artist_similarity_df, artist_id_to_name, top_n=10)\n",
    "\n",
    "# Display item-based recommendations\n",
    "print(\"\\nTop Item-Based Recommendations for User 2:\")\n",
    "for artist_id, artist_name, score in item_based_recommendations:\n",
    "    print(f\"Artist ID: {artist_id}, Artist: {artist_name}, Similarity Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Decomposition Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 artist recommendations for 2:\n",
      "72: Predicted Listening Count = 3145.02\n",
      "792: Predicted Listening Count = 169.15\n",
      "1072: Predicted Listening Count = 107.64\n",
      "1014: Predicted Listening Count = 92.68\n",
      "511: Predicted Listening Count = 87.50\n",
      "\n",
      "MSE between original and reconstructed matrix: 32611.07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Factorize the matrix using Truncated SVD\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "user_factors = svd.fit_transform(user_artist_matrix)  # user latent factors\n",
    "artist_factors = svd.components_  # artist latent factors\n",
    "\n",
    "# Reconstruct the matrix\n",
    "reconstructed_matrix = np.dot(user_factors, artist_factors)\n",
    "\n",
    "# Convert the reconstructed matrix back to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_matrix, columns=user_artist_matrix.columns, index=user_artist_matrix.index)\n",
    "\n",
    "# Example: Get top 5 artist recommendations for user 2\n",
    "user_id = 2\n",
    "top_n = 5\n",
    "user_predictions = reconstructed_df.loc[user_id]\n",
    "top_artists = user_predictions.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "# Display the recommendations\n",
    "print(f\"Top {top_n} artist recommendations for {user_id}:\")\n",
    "for artist, score in top_artists.items():\n",
    "    print(f\"{artist}: Predicted Listening Count = {score:.2f}\")\n",
    "\n",
    "# Evaluate using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(user_artist_matrix.values, reconstructed_matrix)\n",
    "print(f\"\\nMSE between original and reconstructed matrix: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milse\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f8518e02de420fb0fe11cac8de2606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 1:\n",
      "Artist: 715, Score = 1.67\n",
      "Artist: 238, Score = 1.54\n",
      "Artist: 183, Score = 1.36\n",
      "Artist: 1122, Score = 1.35\n",
      "Artist: 1795, Score = 1.28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import implicit\n",
    "\n",
    "# Convert the matrix to a sparse format\n",
    "sparse_matrix = csr_matrix(user_artist_matrix.values)\n",
    "\n",
    "# Initialize and train the ALS model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
    "model.fit(sparse_matrix)\n",
    "\n",
    "# Get recommendations for user 'user1' (index 0)\n",
    "user_id = 0  # 'user1' is at index 0 (if using 0-based indexing)\n",
    "recommendations = model.recommend(user_id, sparse_matrix[user_id], N=5)\n",
    "\n",
    "# Display the top 5 artist recommendations for user1\n",
    "print(f\"Top 5 recommendations for user {user_id + 1}:\")  # Adjust user ID for human-readable format\n",
    "\n",
    "# Recommendations is a tuple of two arrays: artist IDs and scores\n",
    "artist_ids = recommendations[0]\n",
    "scores = recommendations[1]\n",
    "\n",
    "for i in range(len(artist_ids)):\n",
    "    artist_id = artist_ids[i]  # Get the artist ID from the array\n",
    "    score = scores[i]  # Get the corresponding score\n",
    "\n",
    "    # Access the artist name by column index (adjust if needed)\n",
    "    artist_name = user_artist_matrix.columns[artist_id]  # Retrieve artist name from column index\n",
    "    print(f\"Artist: {artist_name}, Score = {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark\n",
    "## Theory\n",
    "EXPLANATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Implementation with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based Implementation with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGH WORK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
